{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import pickle\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "import data_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from random import seed\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f58a6666950>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1234)\n",
    "seed(1234)\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset path\n",
    "data_path = \"./data/var_u.mat\" # Orig IB data\n",
    "\n",
    "# Run on GPU if possible\n",
    "#cuda = torch.cuda.is_available() \n",
    "#device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "#print(\"Using \"+ str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_casting(dataset):\n",
    "    return torch.tensor(dataset.X, dtype=torch.float32), \\\n",
    "           torch.tensor(dataset.y, dtype=torch.float32), \\\n",
    "           torch.tensor(dataset.c, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data...\n"
     ]
    }
   ],
   "source": [
    "trn, tst = utils.get_ib_data()\n",
    "\n",
    "x_train, y_train, c_train = tensor_casting(trn)\n",
    "x_test, y_test, c_test = tensor_casting(tst)\n",
    "\n",
    "data = dict()\n",
    "data['train'] = {}\n",
    "data['train']['samples'] = x_train\n",
    "data['train']['labels'] = y_train\n",
    "data['train']['class'] = c_train\n",
    "data['test'] = {}\n",
    "data['test']['samples'] = x_test\n",
    "data['test']['labels'] = y_test\n",
    "data['test']['class'] = c_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"loss_function\" : nn.BCEWithLogitsLoss(),\n",
    "    \"batch_size\" : 256,\n",
    "    \"epochs\" : 5000,\n",
    "    \"layer_sizes\" : [12,10,7,5,4,3,2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "#X_train, X_test, y_train, y_test = data_utils.load_data(data_path)\n",
    "\n",
    "# Prepare data for pytorch\n",
    "train_loader = data_utils.create_dataloader(x_train, y_train, len(x_train))\n",
    "test_loader = data_utils.create_dataloader(x_test, y_test, len(x_test))\n",
    "\n",
    "full_X, full_y = np.concatenate((x_train, x_test)), np.concatenate((y_train, y_test))\n",
    "eval_loader = data_utils.create_dataloader(x_train, y_train, len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do collect during training.\n",
    "# Gradients of weights for all layers: something like ib_model.h3.weight.grad\n",
    "# Weights for each layer: ib_model.h3.weight\n",
    "# Activity: Save it in the forward pass and keep track of batch things.\n",
    "\n",
    "# Compute L2 norm of weights\n",
    "# Mean of gradients\n",
    "# Std of gradients \n",
    "# Activity <- needed for MI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IBNet(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(IBNet, self).__init__()\n",
    "        torch.manual_seed(1234)\n",
    "        # See https://pytorch.org/docs/stable/nn.html\n",
    "        self.linears = nn.ModuleList()\n",
    "        \n",
    "        self.num_layers = len(cfg[\"layer_sizes\"])\n",
    "        self.inp_size = cfg[\"layer_sizes\"][0]\n",
    "        \n",
    "        h_in = self.inp_size\n",
    "        for h_out in cfg[\"layer_sizes\"][1:]:\n",
    "            self.linears.append(nn.Linear(h_in, h_out))\n",
    "            h_in = h_out\n",
    "    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        activations = [] #TODO: Could be nicer\n",
    "        for idx in range(self.num_layers-1):\n",
    "            x = torch.tanh(self.linears[idx](x))\n",
    "            if idx == self.num_layers-1:\n",
    "                x = self.linears[-1](x)\n",
    "            if not self.training: #Internal flag in model\n",
    "                activations.append(x)\n",
    "         \n",
    "        return x, activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ib_model = IBNet(config)\n",
    "optimizer = optim.Adam(ib_model.parameters(), lr=0.0004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, cfg, model, optimizer):\n",
    "        self.opt = optimizer\n",
    "        self.loss_function = torch.nn.BCEWithLogitsLoss()\n",
    "        self.batch_size = cfg[\"batch_size\"]\n",
    "        self.epochs = cfg[\"epochs\"]\n",
    "        self.model = model\n",
    "        self.hidden_activations = [] # index 1: epoch num, index2 : layer_num\n",
    "        self.weights = dict()\n",
    "        self.ws_grads = dict()\n",
    "        \n",
    "        \n",
    "    def _get_epoch_activity(self, eval_loader, val=False):\n",
    "        \"\"\"\n",
    "        After each epoch save the activation of each hidden layer\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        eval_loss = 0\n",
    "        with torch.no_grad(): # Speeds up very little by turning autograd engine off.\n",
    "            for i, (data, label) in enumerate(eval_loader):# No need to loop.\n",
    "                data, label= data.to(device), label.to(device)\n",
    "                yhat, activations = self.model(data)\n",
    "                eval_loss += nn.BCEWithLogitsLoss()(yhat, label).item()\n",
    "                \n",
    "        if val:\n",
    "            print('Validation loss: {:.7f}'.format(eval_loss))\n",
    "        else:\n",
    "            print('Evaluation loss: {:.7f}'.format(eval_loss))\n",
    "        #print(activations)\n",
    "        return list(map(lambda x:x.cpu().numpy(), activations))\n",
    "    \n",
    "    \n",
    "    def train(self, samples, labels, classes):\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=0.0004)\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        for epoch in range(1, self.epochs+1):\n",
    "            ### START MAIN TRAIN LOOP ###\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            \n",
    "            self.opt.zero_grad()\n",
    "            yhat, _ = self.model(samples)\n",
    "            loss = criterion(yhat, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "              \n",
    "            #print(train_loss)\n",
    "            #acc = (torch.tensor(list(map(torch.argmax, label.cpu()))) == yhat.cpu().argmax(dim=1)).sum() / float(len(label))\n",
    "            #print(\"Accuracy :\", acc)\n",
    "            print('Epoch: {} Train loss: {:.7f}'.format(epoch, loss.item()))\n",
    "            ### STOP MAIN TRAIN LOOP ###\n",
    "                \n",
    "            ### RUN ON VALIDATION DATA ###\n",
    "            #self._get_epoch_activity(test_loader, val=True)\n",
    "            \n",
    "            ### SAVE ACTIVATION ON FULL DATA ###\n",
    "            #self.hidden_activations.append(self._get_epoch_activity(eval_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 0.6978789\n",
      "Epoch: 2 Train loss: 0.6978106\n",
      "Epoch: 3 Train loss: 0.6977426\n",
      "Epoch: 4 Train loss: 0.6976743\n",
      "Epoch: 5 Train loss: 0.6976055\n",
      "Epoch: 6 Train loss: 0.6975372\n",
      "Epoch: 7 Train loss: 0.6974685\n",
      "Epoch: 8 Train loss: 0.6973994\n",
      "Epoch: 9 Train loss: 0.6973305\n",
      "Epoch: 10 Train loss: 0.6972612\n",
      "Epoch: 11 Train loss: 0.6971919\n",
      "Epoch: 12 Train loss: 0.6971222\n",
      "Epoch: 13 Train loss: 0.6970519\n",
      "Epoch: 14 Train loss: 0.6969820\n",
      "Epoch: 15 Train loss: 0.6969118\n",
      "Epoch: 16 Train loss: 0.6968409\n",
      "Epoch: 17 Train loss: 0.6967704\n",
      "Epoch: 18 Train loss: 0.6966990\n",
      "Epoch: 19 Train loss: 0.6966274\n",
      "Epoch: 20 Train loss: 0.6965557\n",
      "Epoch: 21 Train loss: 0.6964837\n",
      "Epoch: 22 Train loss: 0.6964113\n",
      "Epoch: 23 Train loss: 0.6963385\n",
      "Epoch: 24 Train loss: 0.6962656\n",
      "Epoch: 25 Train loss: 0.6961919\n",
      "Epoch: 26 Train loss: 0.6961178\n",
      "Epoch: 27 Train loss: 0.6960434\n",
      "Epoch: 28 Train loss: 0.6959683\n",
      "Epoch: 29 Train loss: 0.6958929\n",
      "Epoch: 30 Train loss: 0.6958172\n",
      "Epoch: 31 Train loss: 0.6957406\n",
      "Epoch: 32 Train loss: 0.6956636\n",
      "Epoch: 33 Train loss: 0.6955861\n",
      "Epoch: 34 Train loss: 0.6955081\n",
      "Epoch: 35 Train loss: 0.6954291\n",
      "Epoch: 36 Train loss: 0.6953498\n",
      "Epoch: 37 Train loss: 0.6952695\n",
      "Epoch: 38 Train loss: 0.6951885\n",
      "Epoch: 39 Train loss: 0.6951072\n",
      "Epoch: 40 Train loss: 0.6950247\n",
      "Epoch: 41 Train loss: 0.6949415\n",
      "Epoch: 42 Train loss: 0.6948576\n",
      "Epoch: 43 Train loss: 0.6947727\n",
      "Epoch: 44 Train loss: 0.6946871\n",
      "Epoch: 45 Train loss: 0.6946007\n",
      "Epoch: 46 Train loss: 0.6945130\n",
      "Epoch: 47 Train loss: 0.6944247\n",
      "Epoch: 48 Train loss: 0.6943354\n",
      "Epoch: 49 Train loss: 0.6942452\n",
      "Epoch: 50 Train loss: 0.6941535\n",
      "Epoch: 51 Train loss: 0.6940612\n",
      "Epoch: 52 Train loss: 0.6939676\n",
      "Epoch: 53 Train loss: 0.6938728\n",
      "Epoch: 54 Train loss: 0.6937774\n",
      "Epoch: 55 Train loss: 0.6936802\n",
      "Epoch: 56 Train loss: 0.6935821\n",
      "Epoch: 57 Train loss: 0.6934828\n",
      "Epoch: 58 Train loss: 0.6933823\n",
      "Epoch: 59 Train loss: 0.6932805\n",
      "Epoch: 60 Train loss: 0.6931772\n",
      "Epoch: 61 Train loss: 0.6930726\n",
      "Epoch: 62 Train loss: 0.6929668\n",
      "Epoch: 63 Train loss: 0.6928596\n",
      "Epoch: 64 Train loss: 0.6927508\n",
      "Epoch: 65 Train loss: 0.6926407\n",
      "Epoch: 66 Train loss: 0.6925292\n",
      "Epoch: 67 Train loss: 0.6924159\n",
      "Epoch: 68 Train loss: 0.6923008\n",
      "Epoch: 69 Train loss: 0.6921846\n",
      "Epoch: 70 Train loss: 0.6920667\n",
      "Epoch: 71 Train loss: 0.6919469\n",
      "Epoch: 72 Train loss: 0.6918256\n",
      "Epoch: 73 Train loss: 0.6917025\n",
      "Epoch: 74 Train loss: 0.6915777\n",
      "Epoch: 75 Train loss: 0.6914509\n",
      "Epoch: 76 Train loss: 0.6913222\n",
      "Epoch: 77 Train loss: 0.6911917\n",
      "Epoch: 78 Train loss: 0.6910592\n",
      "Epoch: 79 Train loss: 0.6909246\n",
      "Epoch: 80 Train loss: 0.6907882\n",
      "Epoch: 81 Train loss: 0.6906494\n",
      "Epoch: 82 Train loss: 0.6905085\n",
      "Epoch: 83 Train loss: 0.6903653\n",
      "Epoch: 84 Train loss: 0.6902205\n",
      "Epoch: 85 Train loss: 0.6900729\n",
      "Epoch: 86 Train loss: 0.6899229\n",
      "Epoch: 87 Train loss: 0.6897706\n",
      "Epoch: 88 Train loss: 0.6896161\n",
      "Epoch: 89 Train loss: 0.6894588\n",
      "Epoch: 90 Train loss: 0.6892991\n",
      "Epoch: 91 Train loss: 0.6891369\n",
      "Epoch: 92 Train loss: 0.6889720\n",
      "Epoch: 93 Train loss: 0.6888046\n",
      "Epoch: 94 Train loss: 0.6886343\n",
      "Epoch: 95 Train loss: 0.6884613\n",
      "Epoch: 96 Train loss: 0.6882856\n",
      "Epoch: 97 Train loss: 0.6881072\n",
      "Epoch: 98 Train loss: 0.6879256\n",
      "Epoch: 99 Train loss: 0.6877410\n",
      "Epoch: 100 Train loss: 0.6875535\n",
      "Epoch: 101 Train loss: 0.6873633\n",
      "Epoch: 102 Train loss: 0.6871697\n",
      "Epoch: 103 Train loss: 0.6869732\n",
      "Epoch: 104 Train loss: 0.6867732\n",
      "Epoch: 105 Train loss: 0.6865699\n",
      "Epoch: 106 Train loss: 0.6863637\n",
      "Epoch: 107 Train loss: 0.6861541\n",
      "Epoch: 108 Train loss: 0.6859410\n",
      "Epoch: 109 Train loss: 0.6857245\n",
      "Epoch: 110 Train loss: 0.6855047\n",
      "Epoch: 111 Train loss: 0.6852813\n",
      "Epoch: 112 Train loss: 0.6850544\n",
      "Epoch: 113 Train loss: 0.6848236\n",
      "Epoch: 114 Train loss: 0.6845896\n",
      "Epoch: 115 Train loss: 0.6843518\n",
      "Epoch: 116 Train loss: 0.6841100\n",
      "Epoch: 117 Train loss: 0.6838645\n",
      "Epoch: 118 Train loss: 0.6836150\n",
      "Epoch: 119 Train loss: 0.6833616\n",
      "Epoch: 120 Train loss: 0.6831043\n",
      "Epoch: 121 Train loss: 0.6828429\n",
      "Epoch: 122 Train loss: 0.6825773\n",
      "Epoch: 123 Train loss: 0.6823075\n",
      "Epoch: 124 Train loss: 0.6820336\n",
      "Epoch: 125 Train loss: 0.6817551\n",
      "Epoch: 126 Train loss: 0.6814724\n",
      "Epoch: 127 Train loss: 0.6811851\n",
      "Epoch: 128 Train loss: 0.6808935\n",
      "Epoch: 129 Train loss: 0.6805969\n",
      "Epoch: 130 Train loss: 0.6802958\n",
      "Epoch: 131 Train loss: 0.6799898\n",
      "Epoch: 132 Train loss: 0.6796786\n",
      "Epoch: 133 Train loss: 0.6793630\n",
      "Epoch: 134 Train loss: 0.6790418\n",
      "Epoch: 135 Train loss: 0.6787158\n",
      "Epoch: 136 Train loss: 0.6783842\n",
      "Epoch: 137 Train loss: 0.6780473\n",
      "Epoch: 138 Train loss: 0.6777051\n",
      "Epoch: 139 Train loss: 0.6773572\n",
      "Epoch: 140 Train loss: 0.6770037\n",
      "Epoch: 141 Train loss: 0.6766446\n",
      "Epoch: 142 Train loss: 0.6762794\n",
      "Epoch: 143 Train loss: 0.6759083\n",
      "Epoch: 144 Train loss: 0.6755312\n",
      "Epoch: 145 Train loss: 0.6751480\n",
      "Epoch: 146 Train loss: 0.6747582\n",
      "Epoch: 147 Train loss: 0.6743624\n",
      "Epoch: 148 Train loss: 0.6739600\n",
      "Epoch: 149 Train loss: 0.6735508\n",
      "Epoch: 150 Train loss: 0.6731350\n",
      "Epoch: 151 Train loss: 0.6727124\n",
      "Epoch: 152 Train loss: 0.6722831\n",
      "Epoch: 153 Train loss: 0.6718467\n",
      "Epoch: 154 Train loss: 0.6714032\n",
      "Epoch: 155 Train loss: 0.6709524\n",
      "Epoch: 156 Train loss: 0.6704943\n",
      "Epoch: 157 Train loss: 0.6700289\n",
      "Epoch: 158 Train loss: 0.6695562\n",
      "Epoch: 159 Train loss: 0.6690759\n",
      "Epoch: 160 Train loss: 0.6685876\n",
      "Epoch: 161 Train loss: 0.6680915\n",
      "Epoch: 162 Train loss: 0.6675881\n",
      "Epoch: 163 Train loss: 0.6670761\n",
      "Epoch: 164 Train loss: 0.6665563\n",
      "Epoch: 165 Train loss: 0.6660285\n",
      "Epoch: 166 Train loss: 0.6654924\n",
      "Epoch: 167 Train loss: 0.6649476\n",
      "Epoch: 168 Train loss: 0.6643947\n",
      "Epoch: 169 Train loss: 0.6638336\n",
      "Epoch: 170 Train loss: 0.6632635\n",
      "Epoch: 171 Train loss: 0.6626847\n",
      "Epoch: 172 Train loss: 0.6620972\n",
      "Epoch: 173 Train loss: 0.6615012\n",
      "Epoch: 174 Train loss: 0.6608959\n",
      "Epoch: 175 Train loss: 0.6602815\n",
      "Epoch: 176 Train loss: 0.6596581\n",
      "Epoch: 177 Train loss: 0.6590261\n",
      "Epoch: 178 Train loss: 0.6583843\n",
      "Epoch: 179 Train loss: 0.6577334\n",
      "Epoch: 180 Train loss: 0.6570730\n",
      "Epoch: 181 Train loss: 0.6564035\n",
      "Epoch: 182 Train loss: 0.6557242\n",
      "Epoch: 183 Train loss: 0.6550354\n",
      "Epoch: 184 Train loss: 0.6543371\n",
      "Epoch: 185 Train loss: 0.6536289\n",
      "Epoch: 186 Train loss: 0.6529114\n",
      "Epoch: 187 Train loss: 0.6521840\n",
      "Epoch: 188 Train loss: 0.6514468\n",
      "Epoch: 189 Train loss: 0.6506997\n",
      "Epoch: 190 Train loss: 0.6499429\n",
      "Epoch: 191 Train loss: 0.6491759\n",
      "Epoch: 192 Train loss: 0.6483994\n",
      "Epoch: 193 Train loss: 0.6476127\n",
      "Epoch: 194 Train loss: 0.6468166\n",
      "Epoch: 195 Train loss: 0.6460100\n",
      "Epoch: 196 Train loss: 0.6451936\n",
      "Epoch: 197 Train loss: 0.6443676\n",
      "Epoch: 198 Train loss: 0.6435312\n",
      "Epoch: 199 Train loss: 0.6426854\n",
      "Epoch: 200 Train loss: 0.6418296\n",
      "Epoch: 201 Train loss: 0.6409637\n",
      "Epoch: 202 Train loss: 0.6400884\n",
      "Epoch: 203 Train loss: 0.6392034\n",
      "Epoch: 204 Train loss: 0.6383082\n",
      "Epoch: 205 Train loss: 0.6374040\n",
      "Epoch: 206 Train loss: 0.6364898\n",
      "Epoch: 207 Train loss: 0.6355664\n",
      "Epoch: 208 Train loss: 0.6346333\n",
      "Epoch: 209 Train loss: 0.6336912\n",
      "Epoch: 210 Train loss: 0.6327394\n",
      "Epoch: 211 Train loss: 0.6317786\n",
      "Epoch: 212 Train loss: 0.6308090\n",
      "Epoch: 213 Train loss: 0.6298303\n",
      "Epoch: 214 Train loss: 0.6288428\n",
      "Epoch: 215 Train loss: 0.6278464\n",
      "Epoch: 216 Train loss: 0.6268420\n",
      "Epoch: 217 Train loss: 0.6258290\n",
      "Epoch: 218 Train loss: 0.6248077\n",
      "Epoch: 219 Train loss: 0.6237783\n",
      "Epoch: 220 Train loss: 0.6227413\n",
      "Epoch: 221 Train loss: 0.6216964\n",
      "Epoch: 222 Train loss: 0.6206439\n",
      "Epoch: 223 Train loss: 0.6195843\n",
      "Epoch: 224 Train loss: 0.6185176\n",
      "Epoch: 225 Train loss: 0.6174439\n",
      "Epoch: 226 Train loss: 0.6163638\n",
      "Epoch: 227 Train loss: 0.6152771\n",
      "Epoch: 228 Train loss: 0.6141844\n",
      "Epoch: 229 Train loss: 0.6130857\n",
      "Epoch: 230 Train loss: 0.6119818\n",
      "Epoch: 231 Train loss: 0.6108724\n",
      "Epoch: 232 Train loss: 0.6097580\n",
      "Epoch: 233 Train loss: 0.6086389\n",
      "Epoch: 234 Train loss: 0.6075153\n",
      "Epoch: 235 Train loss: 0.6063878\n",
      "Epoch: 236 Train loss: 0.6052564\n",
      "Epoch: 237 Train loss: 0.6041217\n",
      "Epoch: 238 Train loss: 0.6029839\n",
      "Epoch: 239 Train loss: 0.6018432\n",
      "Epoch: 240 Train loss: 0.6007002\n",
      "Epoch: 241 Train loss: 0.5995551\n",
      "Epoch: 242 Train loss: 0.5984085\n",
      "Epoch: 243 Train loss: 0.5972602\n",
      "Epoch: 244 Train loss: 0.5961111\n",
      "Epoch: 245 Train loss: 0.5949613\n",
      "Epoch: 246 Train loss: 0.5938113\n",
      "Epoch: 247 Train loss: 0.5926613\n",
      "Epoch: 248 Train loss: 0.5915115\n",
      "Epoch: 249 Train loss: 0.5903629\n",
      "Epoch: 250 Train loss: 0.5892150\n",
      "Epoch: 251 Train loss: 0.5880686\n",
      "Epoch: 252 Train loss: 0.5869240\n",
      "Epoch: 253 Train loss: 0.5857814\n",
      "Epoch: 254 Train loss: 0.5846412\n",
      "Epoch: 255 Train loss: 0.5835037\n",
      "Epoch: 256 Train loss: 0.5823691\n",
      "Epoch: 257 Train loss: 0.5812379\n",
      "Epoch: 258 Train loss: 0.5801101\n",
      "Epoch: 259 Train loss: 0.5789860\n",
      "Epoch: 260 Train loss: 0.5778661\n",
      "Epoch: 261 Train loss: 0.5767505\n",
      "Epoch: 262 Train loss: 0.5756393\n",
      "Epoch: 263 Train loss: 0.5745330\n",
      "Epoch: 264 Train loss: 0.5734316\n",
      "Epoch: 265 Train loss: 0.5723354\n",
      "Epoch: 266 Train loss: 0.5712445\n",
      "Epoch: 267 Train loss: 0.5701592\n",
      "Epoch: 268 Train loss: 0.5690794\n",
      "Epoch: 269 Train loss: 0.5680057\n",
      "Epoch: 270 Train loss: 0.5669380\n",
      "Epoch: 271 Train loss: 0.5658766\n",
      "Epoch: 272 Train loss: 0.5648214\n",
      "Epoch: 273 Train loss: 0.5637725\n",
      "Epoch: 274 Train loss: 0.5627304\n",
      "Epoch: 275 Train loss: 0.5616950\n",
      "Epoch: 276 Train loss: 0.5606664\n",
      "Epoch: 277 Train loss: 0.5596447\n",
      "Epoch: 278 Train loss: 0.5586299\n",
      "Epoch: 279 Train loss: 0.5576224\n",
      "Epoch: 280 Train loss: 0.5566219\n",
      "Epoch: 281 Train loss: 0.5556288\n",
      "Epoch: 282 Train loss: 0.5546429\n",
      "Epoch: 283 Train loss: 0.5536644\n",
      "Epoch: 284 Train loss: 0.5526932\n",
      "Epoch: 285 Train loss: 0.5517297\n",
      "Epoch: 286 Train loss: 0.5507734\n",
      "Epoch: 287 Train loss: 0.5498250\n",
      "Epoch: 288 Train loss: 0.5488839\n",
      "Epoch: 289 Train loss: 0.5479505\n",
      "Epoch: 290 Train loss: 0.5470246\n",
      "Epoch: 291 Train loss: 0.5461064\n",
      "Epoch: 292 Train loss: 0.5451957\n",
      "Epoch: 293 Train loss: 0.5442926\n",
      "Epoch: 294 Train loss: 0.5433972\n",
      "Epoch: 295 Train loss: 0.5425093\n",
      "Epoch: 296 Train loss: 0.5416291\n",
      "Epoch: 297 Train loss: 0.5407566\n",
      "Epoch: 298 Train loss: 0.5398914\n",
      "Epoch: 299 Train loss: 0.5390338\n",
      "Epoch: 300 Train loss: 0.5381840\n",
      "Epoch: 301 Train loss: 0.5373413\n",
      "Epoch: 302 Train loss: 0.5365063\n",
      "Epoch: 303 Train loss: 0.5356787\n",
      "Epoch: 304 Train loss: 0.5348584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 305 Train loss: 0.5340458\n",
      "Epoch: 306 Train loss: 0.5332404\n",
      "Epoch: 307 Train loss: 0.5324423\n",
      "Epoch: 308 Train loss: 0.5316517\n",
      "Epoch: 309 Train loss: 0.5308682\n",
      "Epoch: 310 Train loss: 0.5300921\n",
      "Epoch: 311 Train loss: 0.5293232\n",
      "Epoch: 312 Train loss: 0.5285612\n",
      "Epoch: 313 Train loss: 0.5278066\n",
      "Epoch: 314 Train loss: 0.5270591\n",
      "Epoch: 315 Train loss: 0.5263185\n",
      "Epoch: 316 Train loss: 0.5255851\n",
      "Epoch: 317 Train loss: 0.5248585\n",
      "Epoch: 318 Train loss: 0.5241389\n",
      "Epoch: 319 Train loss: 0.5234261\n",
      "Epoch: 320 Train loss: 0.5227204\n",
      "Epoch: 321 Train loss: 0.5220211\n",
      "Epoch: 322 Train loss: 0.5213289\n",
      "Epoch: 323 Train loss: 0.5206432\n",
      "Epoch: 324 Train loss: 0.5199643\n",
      "Epoch: 325 Train loss: 0.5192918\n",
      "Epoch: 326 Train loss: 0.5186259\n",
      "Epoch: 327 Train loss: 0.5179665\n",
      "Epoch: 328 Train loss: 0.5173136\n",
      "Epoch: 329 Train loss: 0.5166669\n",
      "Epoch: 330 Train loss: 0.5160267\n",
      "Epoch: 331 Train loss: 0.5153925\n",
      "Epoch: 332 Train loss: 0.5147647\n",
      "Epoch: 333 Train loss: 0.5141432\n",
      "Epoch: 334 Train loss: 0.5135274\n",
      "Epoch: 335 Train loss: 0.5129178\n",
      "Epoch: 336 Train loss: 0.5123141\n",
      "Epoch: 337 Train loss: 0.5117162\n",
      "Epoch: 338 Train loss: 0.5111242\n",
      "Epoch: 339 Train loss: 0.5105381\n",
      "Epoch: 340 Train loss: 0.5099575\n",
      "Epoch: 341 Train loss: 0.5093827\n",
      "Epoch: 342 Train loss: 0.5088134\n",
      "Epoch: 343 Train loss: 0.5082496\n",
      "Epoch: 344 Train loss: 0.5076913\n",
      "Epoch: 345 Train loss: 0.5071384\n",
      "Epoch: 346 Train loss: 0.5065908\n",
      "Epoch: 347 Train loss: 0.5060485\n",
      "Epoch: 348 Train loss: 0.5055115\n",
      "Epoch: 349 Train loss: 0.5049794\n",
      "Epoch: 350 Train loss: 0.5044526\n",
      "Epoch: 351 Train loss: 0.5039307\n",
      "Epoch: 352 Train loss: 0.5034139\n",
      "Epoch: 353 Train loss: 0.5029019\n",
      "Epoch: 354 Train loss: 0.5023946\n",
      "Epoch: 355 Train loss: 0.5018921\n",
      "Epoch: 356 Train loss: 0.5013945\n",
      "Epoch: 357 Train loss: 0.5009015\n",
      "Epoch: 358 Train loss: 0.5004131\n",
      "Epoch: 359 Train loss: 0.4999292\n",
      "Epoch: 360 Train loss: 0.4994497\n",
      "Epoch: 361 Train loss: 0.4989749\n",
      "Epoch: 362 Train loss: 0.4985042\n",
      "Epoch: 363 Train loss: 0.4980379\n",
      "Epoch: 364 Train loss: 0.4975760\n",
      "Epoch: 365 Train loss: 0.4971180\n",
      "Epoch: 366 Train loss: 0.4966643\n",
      "Epoch: 367 Train loss: 0.4962146\n",
      "Epoch: 368 Train loss: 0.4957689\n",
      "Epoch: 369 Train loss: 0.4953275\n",
      "Epoch: 370 Train loss: 0.4948896\n",
      "Epoch: 371 Train loss: 0.4944558\n",
      "Epoch: 372 Train loss: 0.4940256\n",
      "Epoch: 373 Train loss: 0.4935992\n",
      "Epoch: 374 Train loss: 0.4931769\n",
      "Epoch: 375 Train loss: 0.4927578\n",
      "Epoch: 376 Train loss: 0.4923425\n",
      "Epoch: 377 Train loss: 0.4919308\n",
      "Epoch: 378 Train loss: 0.4915222\n",
      "Epoch: 379 Train loss: 0.4911175\n",
      "Epoch: 380 Train loss: 0.4907161\n",
      "Epoch: 381 Train loss: 0.4903179\n",
      "Epoch: 382 Train loss: 0.4899232\n",
      "Epoch: 383 Train loss: 0.4895315\n",
      "Epoch: 384 Train loss: 0.4891432\n",
      "Epoch: 385 Train loss: 0.4887580\n",
      "Epoch: 386 Train loss: 0.4883761\n",
      "Epoch: 387 Train loss: 0.4879970\n",
      "Epoch: 388 Train loss: 0.4876210\n",
      "Epoch: 389 Train loss: 0.4872482\n",
      "Epoch: 390 Train loss: 0.4868781\n",
      "Epoch: 391 Train loss: 0.4865108\n",
      "Epoch: 392 Train loss: 0.4861466\n",
      "Epoch: 393 Train loss: 0.4857850\n",
      "Epoch: 394 Train loss: 0.4854264\n",
      "Epoch: 395 Train loss: 0.4850703\n",
      "Epoch: 396 Train loss: 0.4847170\n",
      "Epoch: 397 Train loss: 0.4843664\n",
      "Epoch: 398 Train loss: 0.4840184\n",
      "Epoch: 399 Train loss: 0.4836728\n",
      "Epoch: 400 Train loss: 0.4833298\n",
      "Epoch: 401 Train loss: 0.4829893\n",
      "Epoch: 402 Train loss: 0.4826514\n",
      "Epoch: 403 Train loss: 0.4823158\n",
      "Epoch: 404 Train loss: 0.4819825\n",
      "Epoch: 405 Train loss: 0.4816517\n",
      "Epoch: 406 Train loss: 0.4813231\n",
      "Epoch: 407 Train loss: 0.4809967\n",
      "Epoch: 408 Train loss: 0.4806726\n",
      "Epoch: 409 Train loss: 0.4803508\n",
      "Epoch: 410 Train loss: 0.4800311\n",
      "Epoch: 411 Train loss: 0.4797136\n",
      "Epoch: 412 Train loss: 0.4793982\n",
      "Epoch: 413 Train loss: 0.4790848\n",
      "Epoch: 414 Train loss: 0.4787734\n",
      "Epoch: 415 Train loss: 0.4784642\n",
      "Epoch: 416 Train loss: 0.4781568\n",
      "Epoch: 417 Train loss: 0.4778514\n",
      "Epoch: 418 Train loss: 0.4775480\n",
      "Epoch: 419 Train loss: 0.4772464\n",
      "Epoch: 420 Train loss: 0.4769467\n",
      "Epoch: 421 Train loss: 0.4766487\n",
      "Epoch: 422 Train loss: 0.4763528\n",
      "Epoch: 423 Train loss: 0.4760585\n",
      "Epoch: 424 Train loss: 0.4757660\n",
      "Epoch: 425 Train loss: 0.4754752\n",
      "Epoch: 426 Train loss: 0.4751860\n",
      "Epoch: 427 Train loss: 0.4748986\n",
      "Epoch: 428 Train loss: 0.4746129\n",
      "Epoch: 429 Train loss: 0.4743287\n",
      "Epoch: 430 Train loss: 0.4740462\n",
      "Epoch: 431 Train loss: 0.4737652\n",
      "Epoch: 432 Train loss: 0.4734857\n",
      "Epoch: 433 Train loss: 0.4732080\n",
      "Epoch: 434 Train loss: 0.4729316\n",
      "Epoch: 435 Train loss: 0.4726566\n",
      "Epoch: 436 Train loss: 0.4723832\n",
      "Epoch: 437 Train loss: 0.4721112\n",
      "Epoch: 438 Train loss: 0.4718406\n",
      "Epoch: 439 Train loss: 0.4715716\n",
      "Epoch: 440 Train loss: 0.4713039\n",
      "Epoch: 441 Train loss: 0.4710374\n",
      "Epoch: 442 Train loss: 0.4707723\n",
      "Epoch: 443 Train loss: 0.4705086\n",
      "Epoch: 444 Train loss: 0.4702461\n",
      "Epoch: 445 Train loss: 0.4699850\n",
      "Epoch: 446 Train loss: 0.4697252\n",
      "Epoch: 447 Train loss: 0.4694664\n",
      "Epoch: 448 Train loss: 0.4692091\n",
      "Epoch: 449 Train loss: 0.4689528\n",
      "Epoch: 450 Train loss: 0.4686979\n",
      "Epoch: 451 Train loss: 0.4684441\n",
      "Epoch: 452 Train loss: 0.4681915\n",
      "Epoch: 453 Train loss: 0.4679399\n",
      "Epoch: 454 Train loss: 0.4676897\n",
      "Epoch: 455 Train loss: 0.4674406\n",
      "Epoch: 456 Train loss: 0.4671924\n",
      "Epoch: 457 Train loss: 0.4669453\n",
      "Epoch: 458 Train loss: 0.4666996\n",
      "Epoch: 459 Train loss: 0.4664546\n",
      "Epoch: 460 Train loss: 0.4662108\n",
      "Epoch: 461 Train loss: 0.4659681\n",
      "Epoch: 462 Train loss: 0.4657266\n",
      "Epoch: 463 Train loss: 0.4654857\n",
      "Epoch: 464 Train loss: 0.4652459\n",
      "Epoch: 465 Train loss: 0.4650071\n",
      "Epoch: 466 Train loss: 0.4647694\n",
      "Epoch: 467 Train loss: 0.4645326\n",
      "Epoch: 468 Train loss: 0.4642969\n",
      "Epoch: 469 Train loss: 0.4640619\n",
      "Epoch: 470 Train loss: 0.4638280\n",
      "Epoch: 471 Train loss: 0.4635949\n",
      "Epoch: 472 Train loss: 0.4633628\n",
      "Epoch: 473 Train loss: 0.4631316\n",
      "Epoch: 474 Train loss: 0.4629014\n",
      "Epoch: 475 Train loss: 0.4626719\n",
      "Epoch: 476 Train loss: 0.4624434\n",
      "Epoch: 477 Train loss: 0.4622156\n",
      "Epoch: 478 Train loss: 0.4619887\n",
      "Epoch: 479 Train loss: 0.4617627\n",
      "Epoch: 480 Train loss: 0.4615377\n",
      "Epoch: 481 Train loss: 0.4613132\n",
      "Epoch: 482 Train loss: 0.4610898\n",
      "Epoch: 483 Train loss: 0.4608670\n",
      "Epoch: 484 Train loss: 0.4606452\n",
      "Epoch: 485 Train loss: 0.4604240\n",
      "Epoch: 486 Train loss: 0.4602038\n",
      "Epoch: 487 Train loss: 0.4599842\n",
      "Epoch: 488 Train loss: 0.4597655\n",
      "Epoch: 489 Train loss: 0.4595474\n",
      "Epoch: 490 Train loss: 0.4593303\n",
      "Epoch: 491 Train loss: 0.4591139\n",
      "Epoch: 492 Train loss: 0.4588980\n",
      "Epoch: 493 Train loss: 0.4586830\n",
      "Epoch: 494 Train loss: 0.4584688\n",
      "Epoch: 495 Train loss: 0.4582552\n",
      "Epoch: 496 Train loss: 0.4580424\n",
      "Epoch: 497 Train loss: 0.4578302\n",
      "Epoch: 498 Train loss: 0.4576187\n",
      "Epoch: 499 Train loss: 0.4574081\n",
      "Epoch: 500 Train loss: 0.4571981\n",
      "Epoch: 501 Train loss: 0.4569888\n",
      "Epoch: 502 Train loss: 0.4567801\n",
      "Epoch: 503 Train loss: 0.4565720\n",
      "Epoch: 504 Train loss: 0.4563647\n",
      "Epoch: 505 Train loss: 0.4561581\n",
      "Epoch: 506 Train loss: 0.4559520\n",
      "Epoch: 507 Train loss: 0.4557467\n",
      "Epoch: 508 Train loss: 0.4555421\n",
      "Epoch: 509 Train loss: 0.4553378\n",
      "Epoch: 510 Train loss: 0.4551345\n",
      "Epoch: 511 Train loss: 0.4549315\n",
      "Epoch: 512 Train loss: 0.4547294\n",
      "Epoch: 513 Train loss: 0.4545278\n",
      "Epoch: 514 Train loss: 0.4543266\n",
      "Epoch: 515 Train loss: 0.4541263\n",
      "Epoch: 516 Train loss: 0.4539266\n",
      "Epoch: 517 Train loss: 0.4537276\n",
      "Epoch: 518 Train loss: 0.4535288\n",
      "Epoch: 519 Train loss: 0.4533308\n",
      "Epoch: 520 Train loss: 0.4531333\n",
      "Epoch: 521 Train loss: 0.4529364\n",
      "Epoch: 522 Train loss: 0.4527403\n",
      "Epoch: 523 Train loss: 0.4525445\n",
      "Epoch: 524 Train loss: 0.4523494\n",
      "Epoch: 525 Train loss: 0.4521547\n",
      "Epoch: 526 Train loss: 0.4519606\n",
      "Epoch: 527 Train loss: 0.4517670\n",
      "Epoch: 528 Train loss: 0.4515740\n",
      "Epoch: 529 Train loss: 0.4513816\n",
      "Epoch: 530 Train loss: 0.4511896\n",
      "Epoch: 531 Train loss: 0.4509983\n",
      "Epoch: 532 Train loss: 0.4508074\n",
      "Epoch: 533 Train loss: 0.4506171\n",
      "Epoch: 534 Train loss: 0.4504271\n",
      "Epoch: 535 Train loss: 0.4502378\n",
      "Epoch: 536 Train loss: 0.4500491\n",
      "Epoch: 537 Train loss: 0.4498607\n",
      "Epoch: 538 Train loss: 0.4496728\n",
      "Epoch: 539 Train loss: 0.4494854\n",
      "Epoch: 540 Train loss: 0.4492986\n",
      "Epoch: 541 Train loss: 0.4491122\n",
      "Epoch: 542 Train loss: 0.4489263\n",
      "Epoch: 543 Train loss: 0.4487408\n",
      "Epoch: 544 Train loss: 0.4485558\n",
      "Epoch: 545 Train loss: 0.4483713\n",
      "Epoch: 546 Train loss: 0.4481872\n",
      "Epoch: 547 Train loss: 0.4480037\n",
      "Epoch: 548 Train loss: 0.4478205\n",
      "Epoch: 549 Train loss: 0.4476379\n",
      "Epoch: 550 Train loss: 0.4474555\n",
      "Epoch: 551 Train loss: 0.4472739\n",
      "Epoch: 552 Train loss: 0.4470923\n",
      "Epoch: 553 Train loss: 0.4469114\n",
      "Epoch: 554 Train loss: 0.4467309\n",
      "Epoch: 555 Train loss: 0.4465508\n",
      "Epoch: 556 Train loss: 0.4463711\n",
      "Epoch: 557 Train loss: 0.4461918\n",
      "Epoch: 558 Train loss: 0.4460130\n",
      "Epoch: 559 Train loss: 0.4458345\n",
      "Epoch: 560 Train loss: 0.4456564\n",
      "Epoch: 561 Train loss: 0.4454789\n",
      "Epoch: 562 Train loss: 0.4453016\n",
      "Epoch: 563 Train loss: 0.4451247\n",
      "Epoch: 564 Train loss: 0.4449482\n",
      "Epoch: 565 Train loss: 0.4447723\n",
      "Epoch: 566 Train loss: 0.4445965\n",
      "Epoch: 567 Train loss: 0.4444212\n",
      "Epoch: 568 Train loss: 0.4442463\n",
      "Epoch: 569 Train loss: 0.4440717\n",
      "Epoch: 570 Train loss: 0.4438974\n",
      "Epoch: 571 Train loss: 0.4437237\n",
      "Epoch: 572 Train loss: 0.4435502\n",
      "Epoch: 573 Train loss: 0.4433771\n",
      "Epoch: 574 Train loss: 0.4432043\n",
      "Epoch: 575 Train loss: 0.4430319\n",
      "Epoch: 576 Train loss: 0.4428598\n",
      "Epoch: 577 Train loss: 0.4426882\n",
      "Epoch: 578 Train loss: 0.4425168\n",
      "Epoch: 579 Train loss: 0.4423457\n",
      "Epoch: 580 Train loss: 0.4421751\n",
      "Epoch: 581 Train loss: 0.4420046\n",
      "Epoch: 582 Train loss: 0.4418347\n",
      "Epoch: 583 Train loss: 0.4416650\n",
      "Epoch: 584 Train loss: 0.4414955\n",
      "Epoch: 585 Train loss: 0.4413265\n",
      "Epoch: 586 Train loss: 0.4411576\n",
      "Epoch: 587 Train loss: 0.4409893\n",
      "Epoch: 588 Train loss: 0.4408211\n",
      "Epoch: 589 Train loss: 0.4406534\n",
      "Epoch: 590 Train loss: 0.4404858\n",
      "Epoch: 591 Train loss: 0.4403186\n",
      "Epoch: 592 Train loss: 0.4401517\n",
      "Epoch: 593 Train loss: 0.4399851\n",
      "Epoch: 594 Train loss: 0.4398187\n",
      "Epoch: 595 Train loss: 0.4396527\n",
      "Epoch: 596 Train loss: 0.4394870\n",
      "Epoch: 597 Train loss: 0.4393215\n",
      "Epoch: 598 Train loss: 0.4391563\n",
      "Epoch: 599 Train loss: 0.4389914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 600 Train loss: 0.4388267\n",
      "Epoch: 601 Train loss: 0.4386624\n",
      "Epoch: 602 Train loss: 0.4384985\n",
      "Epoch: 603 Train loss: 0.4383345\n",
      "Epoch: 604 Train loss: 0.4381710\n",
      "Epoch: 605 Train loss: 0.4380077\n",
      "Epoch: 606 Train loss: 0.4378448\n",
      "Epoch: 607 Train loss: 0.4376822\n",
      "Epoch: 608 Train loss: 0.4375194\n",
      "Epoch: 609 Train loss: 0.4373573\n",
      "Epoch: 610 Train loss: 0.4371952\n",
      "Epoch: 611 Train loss: 0.4370336\n",
      "Epoch: 612 Train loss: 0.4368722\n",
      "Epoch: 613 Train loss: 0.4367107\n",
      "Epoch: 614 Train loss: 0.4365498\n",
      "Epoch: 615 Train loss: 0.4363891\n",
      "Epoch: 616 Train loss: 0.4362285\n",
      "Epoch: 617 Train loss: 0.4360682\n",
      "Epoch: 618 Train loss: 0.4359083\n",
      "Epoch: 619 Train loss: 0.4357482\n",
      "Epoch: 620 Train loss: 0.4355887\n",
      "Epoch: 621 Train loss: 0.4354293\n",
      "Epoch: 622 Train loss: 0.4352700\n",
      "Epoch: 623 Train loss: 0.4351112\n",
      "Epoch: 624 Train loss: 0.4349523\n",
      "Epoch: 625 Train loss: 0.4347938\n",
      "Epoch: 626 Train loss: 0.4346355\n",
      "Epoch: 627 Train loss: 0.4344774\n",
      "Epoch: 628 Train loss: 0.4343195\n",
      "Epoch: 629 Train loss: 0.4341618\n",
      "Epoch: 630 Train loss: 0.4340042\n",
      "Epoch: 631 Train loss: 0.4338470\n",
      "Epoch: 632 Train loss: 0.4336897\n",
      "Epoch: 633 Train loss: 0.4335329\n",
      "Epoch: 634 Train loss: 0.4333763\n",
      "Epoch: 635 Train loss: 0.4332197\n",
      "Epoch: 636 Train loss: 0.4330633\n",
      "Epoch: 637 Train loss: 0.4329071\n",
      "Epoch: 638 Train loss: 0.4327510\n",
      "Epoch: 639 Train loss: 0.4325952\n",
      "Epoch: 640 Train loss: 0.4324395\n",
      "Epoch: 641 Train loss: 0.4322842\n",
      "Epoch: 642 Train loss: 0.4321287\n",
      "Epoch: 643 Train loss: 0.4319736\n",
      "Epoch: 644 Train loss: 0.4318187\n",
      "Epoch: 645 Train loss: 0.4316638\n",
      "Epoch: 646 Train loss: 0.4315090\n",
      "Epoch: 647 Train loss: 0.4313545\n",
      "Epoch: 648 Train loss: 0.4312002\n",
      "Epoch: 649 Train loss: 0.4310460\n",
      "Epoch: 650 Train loss: 0.4308918\n",
      "Epoch: 651 Train loss: 0.4307379\n",
      "Epoch: 652 Train loss: 0.4305842\n",
      "Epoch: 653 Train loss: 0.4304305\n",
      "Epoch: 654 Train loss: 0.4302769\n",
      "Epoch: 655 Train loss: 0.4301236\n",
      "Epoch: 656 Train loss: 0.4299704\n",
      "Epoch: 657 Train loss: 0.4298171\n",
      "Epoch: 658 Train loss: 0.4296641\n",
      "Epoch: 659 Train loss: 0.4295113\n",
      "Epoch: 660 Train loss: 0.4293587\n",
      "Epoch: 661 Train loss: 0.4292059\n",
      "Epoch: 662 Train loss: 0.4290533\n",
      "Epoch: 663 Train loss: 0.4289009\n",
      "Epoch: 664 Train loss: 0.4287487\n",
      "Epoch: 665 Train loss: 0.4285963\n",
      "Epoch: 666 Train loss: 0.4284442\n",
      "Epoch: 667 Train loss: 0.4282922\n",
      "Epoch: 668 Train loss: 0.4281403\n",
      "Epoch: 669 Train loss: 0.4279886\n",
      "Epoch: 670 Train loss: 0.4278368\n",
      "Epoch: 671 Train loss: 0.4276851\n",
      "Epoch: 672 Train loss: 0.4275335\n",
      "Epoch: 673 Train loss: 0.4273821\n",
      "Epoch: 674 Train loss: 0.4272307\n",
      "Epoch: 675 Train loss: 0.4270792\n",
      "Epoch: 676 Train loss: 0.4269280\n",
      "Epoch: 677 Train loss: 0.4267768\n",
      "Epoch: 678 Train loss: 0.4266256\n",
      "Epoch: 679 Train loss: 0.4264745\n",
      "Epoch: 680 Train loss: 0.4263235\n",
      "Epoch: 681 Train loss: 0.4261726\n",
      "Epoch: 682 Train loss: 0.4260217\n",
      "Epoch: 683 Train loss: 0.4258709\n",
      "Epoch: 684 Train loss: 0.4257199\n",
      "Epoch: 685 Train loss: 0.4255692\n",
      "Epoch: 686 Train loss: 0.4254185\n",
      "Epoch: 687 Train loss: 0.4252678\n",
      "Epoch: 688 Train loss: 0.4251171\n",
      "Epoch: 689 Train loss: 0.4249664\n",
      "Epoch: 690 Train loss: 0.4248159\n",
      "Epoch: 691 Train loss: 0.4246653\n",
      "Epoch: 692 Train loss: 0.4245148\n",
      "Epoch: 693 Train loss: 0.4243641\n",
      "Epoch: 694 Train loss: 0.4242136\n",
      "Epoch: 695 Train loss: 0.4240631\n",
      "Epoch: 696 Train loss: 0.4239126\n",
      "Epoch: 697 Train loss: 0.4237621\n",
      "Epoch: 698 Train loss: 0.4236115\n",
      "Epoch: 699 Train loss: 0.4234610\n",
      "Epoch: 700 Train loss: 0.4233106\n",
      "Epoch: 701 Train loss: 0.4231600\n",
      "Epoch: 702 Train loss: 0.4230094\n",
      "Epoch: 703 Train loss: 0.4228590\n",
      "Epoch: 704 Train loss: 0.4227083\n",
      "Epoch: 705 Train loss: 0.4225576\n",
      "Epoch: 706 Train loss: 0.4224070\n",
      "Epoch: 707 Train loss: 0.4222564\n",
      "Epoch: 708 Train loss: 0.4221056\n",
      "Epoch: 709 Train loss: 0.4219549\n",
      "Epoch: 710 Train loss: 0.4218041\n",
      "Epoch: 711 Train loss: 0.4216534\n",
      "Epoch: 712 Train loss: 0.4215024\n",
      "Epoch: 713 Train loss: 0.4213514\n",
      "Epoch: 714 Train loss: 0.4212007\n",
      "Epoch: 715 Train loss: 0.4210495\n",
      "Epoch: 716 Train loss: 0.4208984\n",
      "Epoch: 717 Train loss: 0.4207473\n",
      "Epoch: 718 Train loss: 0.4205962\n",
      "Epoch: 719 Train loss: 0.4204448\n",
      "Epoch: 720 Train loss: 0.4202934\n",
      "Epoch: 721 Train loss: 0.4201418\n",
      "Epoch: 722 Train loss: 0.4199904\n",
      "Epoch: 723 Train loss: 0.4198387\n",
      "Epoch: 724 Train loss: 0.4196871\n",
      "Epoch: 725 Train loss: 0.4195352\n",
      "Epoch: 726 Train loss: 0.4193833\n",
      "Epoch: 727 Train loss: 0.4192315\n",
      "Epoch: 728 Train loss: 0.4190794\n",
      "Epoch: 729 Train loss: 0.4189270\n",
      "Epoch: 730 Train loss: 0.4187748\n",
      "Epoch: 731 Train loss: 0.4186223\n",
      "Epoch: 732 Train loss: 0.4184699\n",
      "Epoch: 733 Train loss: 0.4183171\n",
      "Epoch: 734 Train loss: 0.4181644\n",
      "Epoch: 735 Train loss: 0.4180114\n",
      "Epoch: 736 Train loss: 0.4178583\n",
      "Epoch: 737 Train loss: 0.4177053\n",
      "Epoch: 738 Train loss: 0.4175519\n",
      "Epoch: 739 Train loss: 0.4173985\n",
      "Epoch: 740 Train loss: 0.4172449\n",
      "Epoch: 741 Train loss: 0.4170912\n",
      "Epoch: 742 Train loss: 0.4169371\n",
      "Epoch: 743 Train loss: 0.4167832\n",
      "Epoch: 744 Train loss: 0.4166290\n",
      "Epoch: 745 Train loss: 0.4164747\n",
      "Epoch: 746 Train loss: 0.4163201\n",
      "Epoch: 747 Train loss: 0.4161654\n",
      "Epoch: 748 Train loss: 0.4160106\n",
      "Epoch: 749 Train loss: 0.4158555\n",
      "Epoch: 750 Train loss: 0.4157005\n",
      "Epoch: 751 Train loss: 0.4155450\n",
      "Epoch: 752 Train loss: 0.4153895\n",
      "Epoch: 753 Train loss: 0.4152339\n",
      "Epoch: 754 Train loss: 0.4150780\n",
      "Epoch: 755 Train loss: 0.4149219\n",
      "Epoch: 756 Train loss: 0.4147657\n",
      "Epoch: 757 Train loss: 0.4146092\n",
      "Epoch: 758 Train loss: 0.4144524\n",
      "Epoch: 759 Train loss: 0.4142956\n",
      "Epoch: 760 Train loss: 0.4141386\n",
      "Epoch: 761 Train loss: 0.4139813\n",
      "Epoch: 762 Train loss: 0.4138238\n",
      "Epoch: 763 Train loss: 0.4136662\n",
      "Epoch: 764 Train loss: 0.4135082\n",
      "Epoch: 765 Train loss: 0.4133500\n",
      "Epoch: 766 Train loss: 0.4131918\n",
      "Epoch: 767 Train loss: 0.4130332\n",
      "Epoch: 768 Train loss: 0.4128745\n",
      "Epoch: 769 Train loss: 0.4127154\n",
      "Epoch: 770 Train loss: 0.4125561\n",
      "Epoch: 771 Train loss: 0.4123967\n",
      "Epoch: 772 Train loss: 0.4122370\n",
      "Epoch: 773 Train loss: 0.4120772\n",
      "Epoch: 774 Train loss: 0.4119170\n",
      "Epoch: 775 Train loss: 0.4117563\n",
      "Epoch: 776 Train loss: 0.4115958\n",
      "Epoch: 777 Train loss: 0.4114349\n",
      "Epoch: 778 Train loss: 0.4112739\n",
      "Epoch: 779 Train loss: 0.4111124\n",
      "Epoch: 780 Train loss: 0.4109508\n",
      "Epoch: 781 Train loss: 0.4107888\n",
      "Epoch: 782 Train loss: 0.4106267\n",
      "Epoch: 783 Train loss: 0.4104642\n",
      "Epoch: 784 Train loss: 0.4103017\n",
      "Epoch: 785 Train loss: 0.4101388\n",
      "Epoch: 786 Train loss: 0.4099755\n",
      "Epoch: 787 Train loss: 0.4098120\n",
      "Epoch: 788 Train loss: 0.4096484\n",
      "Epoch: 789 Train loss: 0.4094844\n",
      "Epoch: 790 Train loss: 0.4093201\n",
      "Epoch: 791 Train loss: 0.4091555\n",
      "Epoch: 792 Train loss: 0.4089908\n",
      "Epoch: 793 Train loss: 0.4088258\n",
      "Epoch: 794 Train loss: 0.4086606\n",
      "Epoch: 795 Train loss: 0.4084950\n",
      "Epoch: 796 Train loss: 0.4083292\n",
      "Epoch: 797 Train loss: 0.4081632\n",
      "Epoch: 798 Train loss: 0.4079967\n",
      "Epoch: 799 Train loss: 0.4078302\n",
      "Epoch: 800 Train loss: 0.4076634\n",
      "Epoch: 801 Train loss: 0.4074963\n",
      "Epoch: 802 Train loss: 0.4073290\n",
      "Epoch: 803 Train loss: 0.4071612\n",
      "Epoch: 804 Train loss: 0.4069933\n",
      "Epoch: 805 Train loss: 0.4068252\n",
      "Epoch: 806 Train loss: 0.4066570\n",
      "Epoch: 807 Train loss: 0.4064881\n",
      "Epoch: 808 Train loss: 0.4063193\n",
      "Epoch: 809 Train loss: 0.4061502\n",
      "Epoch: 810 Train loss: 0.4059806\n",
      "Epoch: 811 Train loss: 0.4058110\n",
      "Epoch: 812 Train loss: 0.4056411\n",
      "Epoch: 813 Train loss: 0.4054709\n",
      "Epoch: 814 Train loss: 0.4053005\n",
      "Epoch: 815 Train loss: 0.4051299\n",
      "Epoch: 816 Train loss: 0.4049590\n",
      "Epoch: 817 Train loss: 0.4047878\n",
      "Epoch: 818 Train loss: 0.4046163\n",
      "Epoch: 819 Train loss: 0.4044446\n",
      "Epoch: 820 Train loss: 0.4042726\n",
      "Epoch: 821 Train loss: 0.4041004\n",
      "Epoch: 822 Train loss: 0.4039279\n",
      "Epoch: 823 Train loss: 0.4037551\n",
      "Epoch: 824 Train loss: 0.4035819\n",
      "Epoch: 825 Train loss: 0.4034087\n",
      "Epoch: 826 Train loss: 0.4032350\n",
      "Epoch: 827 Train loss: 0.4030610\n",
      "Epoch: 828 Train loss: 0.4028867\n",
      "Epoch: 829 Train loss: 0.4027122\n",
      "Epoch: 830 Train loss: 0.4025372\n",
      "Epoch: 831 Train loss: 0.4023619\n",
      "Epoch: 832 Train loss: 0.4021864\n",
      "Epoch: 833 Train loss: 0.4020105\n",
      "Epoch: 834 Train loss: 0.4018342\n",
      "Epoch: 835 Train loss: 0.4016576\n",
      "Epoch: 836 Train loss: 0.4014805\n",
      "Epoch: 837 Train loss: 0.4013031\n",
      "Epoch: 838 Train loss: 0.4011251\n",
      "Epoch: 839 Train loss: 0.4009469\n",
      "Epoch: 840 Train loss: 0.4007681\n",
      "Epoch: 841 Train loss: 0.4005888\n",
      "Epoch: 842 Train loss: 0.4004092\n",
      "Epoch: 843 Train loss: 0.4002292\n",
      "Epoch: 844 Train loss: 0.4000484\n",
      "Epoch: 845 Train loss: 0.3998673\n",
      "Epoch: 846 Train loss: 0.3996858\n",
      "Epoch: 847 Train loss: 0.3995037\n",
      "Epoch: 848 Train loss: 0.3993209\n",
      "Epoch: 849 Train loss: 0.3991377\n",
      "Epoch: 850 Train loss: 0.3989540\n",
      "Epoch: 851 Train loss: 0.3987697\n",
      "Epoch: 852 Train loss: 0.3985849\n",
      "Epoch: 853 Train loss: 0.3983997\n",
      "Epoch: 854 Train loss: 0.3982136\n",
      "Epoch: 855 Train loss: 0.3980271\n",
      "Epoch: 856 Train loss: 0.3978401\n",
      "Epoch: 857 Train loss: 0.3976527\n",
      "Epoch: 858 Train loss: 0.3974649\n",
      "Epoch: 859 Train loss: 0.3972763\n",
      "Epoch: 860 Train loss: 0.3970875\n",
      "Epoch: 861 Train loss: 0.3968983\n",
      "Epoch: 862 Train loss: 0.3967086\n",
      "Epoch: 863 Train loss: 0.3965185\n",
      "Epoch: 864 Train loss: 0.3963283\n",
      "Epoch: 865 Train loss: 0.3961377\n",
      "Epoch: 866 Train loss: 0.3959471\n",
      "Epoch: 867 Train loss: 0.3957563\n",
      "Epoch: 868 Train loss: 0.3955653\n",
      "Epoch: 869 Train loss: 0.3953741\n",
      "Epoch: 870 Train loss: 0.3951832\n",
      "Epoch: 871 Train loss: 0.3949924\n",
      "Epoch: 872 Train loss: 0.3948016\n",
      "Epoch: 873 Train loss: 0.3946111\n",
      "Epoch: 874 Train loss: 0.3944208\n",
      "Epoch: 875 Train loss: 0.3942309\n",
      "Epoch: 876 Train loss: 0.3940412\n",
      "Epoch: 877 Train loss: 0.3938520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 878 Train loss: 0.3936634\n",
      "Epoch: 879 Train loss: 0.3934753\n",
      "Epoch: 880 Train loss: 0.3932876\n",
      "Epoch: 881 Train loss: 0.3931006\n",
      "Epoch: 882 Train loss: 0.3929142\n",
      "Epoch: 883 Train loss: 0.3927284\n",
      "Epoch: 884 Train loss: 0.3925434\n",
      "Epoch: 885 Train loss: 0.3923592\n",
      "Epoch: 886 Train loss: 0.3921756\n",
      "Epoch: 887 Train loss: 0.3919928\n",
      "Epoch: 888 Train loss: 0.3918109\n",
      "Epoch: 889 Train loss: 0.3916296\n",
      "Epoch: 890 Train loss: 0.3914493\n",
      "Epoch: 891 Train loss: 0.3912698\n",
      "Epoch: 892 Train loss: 0.3910912\n",
      "Epoch: 893 Train loss: 0.3909133\n",
      "Epoch: 894 Train loss: 0.3907363\n",
      "Epoch: 895 Train loss: 0.3905604\n",
      "Epoch: 896 Train loss: 0.3903854\n",
      "Epoch: 897 Train loss: 0.3902110\n",
      "Epoch: 898 Train loss: 0.3900377\n",
      "Epoch: 899 Train loss: 0.3898651\n",
      "Epoch: 900 Train loss: 0.3896936\n",
      "Epoch: 901 Train loss: 0.3895231\n",
      "Epoch: 902 Train loss: 0.3893533\n",
      "Epoch: 903 Train loss: 0.3891847\n",
      "Epoch: 904 Train loss: 0.3890167\n",
      "Epoch: 905 Train loss: 0.3888499\n",
      "Epoch: 906 Train loss: 0.3886836\n",
      "Epoch: 907 Train loss: 0.3885187\n",
      "Epoch: 908 Train loss: 0.3883544\n",
      "Epoch: 909 Train loss: 0.3881911\n",
      "Epoch: 910 Train loss: 0.3880287\n",
      "Epoch: 911 Train loss: 0.3878671\n",
      "Epoch: 912 Train loss: 0.3877064\n",
      "Epoch: 913 Train loss: 0.3875467\n",
      "Epoch: 914 Train loss: 0.3873877\n",
      "Epoch: 915 Train loss: 0.3872296\n",
      "Epoch: 916 Train loss: 0.3870723\n",
      "Epoch: 917 Train loss: 0.3869158\n",
      "Epoch: 918 Train loss: 0.3867603\n",
      "Epoch: 919 Train loss: 0.3866055\n",
      "Epoch: 920 Train loss: 0.3864515\n",
      "Epoch: 921 Train loss: 0.3862983\n",
      "Epoch: 922 Train loss: 0.3861459\n",
      "Epoch: 923 Train loss: 0.3859942\n",
      "Epoch: 924 Train loss: 0.3858433\n",
      "Epoch: 925 Train loss: 0.3856932\n",
      "Epoch: 926 Train loss: 0.3855438\n",
      "Epoch: 927 Train loss: 0.3853949\n",
      "Epoch: 928 Train loss: 0.3852470\n",
      "Epoch: 929 Train loss: 0.3850997\n",
      "Epoch: 930 Train loss: 0.3849529\n",
      "Epoch: 931 Train loss: 0.3848069\n",
      "Epoch: 932 Train loss: 0.3846615\n",
      "Epoch: 933 Train loss: 0.3845169\n",
      "Epoch: 934 Train loss: 0.3843729\n",
      "Epoch: 935 Train loss: 0.3842292\n",
      "Epoch: 936 Train loss: 0.3840862\n",
      "Epoch: 937 Train loss: 0.3839440\n",
      "Epoch: 938 Train loss: 0.3838022\n",
      "Epoch: 939 Train loss: 0.3836610\n",
      "Epoch: 940 Train loss: 0.3835204\n",
      "Epoch: 941 Train loss: 0.3833802\n",
      "Epoch: 942 Train loss: 0.3832406\n",
      "Epoch: 943 Train loss: 0.3831016\n",
      "Epoch: 944 Train loss: 0.3829629\n",
      "Epoch: 945 Train loss: 0.3828247\n",
      "Epoch: 946 Train loss: 0.3826872\n",
      "Epoch: 947 Train loss: 0.3825500\n",
      "Epoch: 948 Train loss: 0.3824131\n",
      "Epoch: 949 Train loss: 0.3822769\n",
      "Epoch: 950 Train loss: 0.3821408\n",
      "Epoch: 951 Train loss: 0.3820051\n",
      "Epoch: 952 Train loss: 0.3818700\n",
      "Epoch: 953 Train loss: 0.3817350\n",
      "Epoch: 954 Train loss: 0.3816006\n",
      "Epoch: 955 Train loss: 0.3814663\n",
      "Epoch: 956 Train loss: 0.3813323\n",
      "Epoch: 957 Train loss: 0.3811987\n",
      "Epoch: 958 Train loss: 0.3810654\n",
      "Epoch: 959 Train loss: 0.3809321\n",
      "Epoch: 960 Train loss: 0.3807991\n",
      "Epoch: 961 Train loss: 0.3806663\n",
      "Epoch: 962 Train loss: 0.3805335\n",
      "Epoch: 963 Train loss: 0.3804009\n",
      "Epoch: 964 Train loss: 0.3802684\n",
      "Epoch: 965 Train loss: 0.3801360\n",
      "Epoch: 966 Train loss: 0.3800036\n",
      "Epoch: 967 Train loss: 0.3798711\n",
      "Epoch: 968 Train loss: 0.3797384\n",
      "Epoch: 969 Train loss: 0.3796056\n",
      "Epoch: 970 Train loss: 0.3794728\n",
      "Epoch: 971 Train loss: 0.3793397\n",
      "Epoch: 972 Train loss: 0.3792064\n",
      "Epoch: 973 Train loss: 0.3790727\n",
      "Epoch: 974 Train loss: 0.3789386\n",
      "Epoch: 975 Train loss: 0.3788042\n",
      "Epoch: 976 Train loss: 0.3786692\n",
      "Epoch: 977 Train loss: 0.3785336\n",
      "Epoch: 978 Train loss: 0.3783974\n",
      "Epoch: 979 Train loss: 0.3782605\n",
      "Epoch: 980 Train loss: 0.3781230\n",
      "Epoch: 981 Train loss: 0.3779843\n",
      "Epoch: 982 Train loss: 0.3778450\n",
      "Epoch: 983 Train loss: 0.3777046\n",
      "Epoch: 984 Train loss: 0.3775633\n",
      "Epoch: 985 Train loss: 0.3774210\n",
      "Epoch: 986 Train loss: 0.3772774\n",
      "Epoch: 987 Train loss: 0.3771329\n",
      "Epoch: 988 Train loss: 0.3769876\n",
      "Epoch: 989 Train loss: 0.3768412\n",
      "Epoch: 990 Train loss: 0.3766938\n",
      "Epoch: 991 Train loss: 0.3765453\n",
      "Epoch: 992 Train loss: 0.3763961\n",
      "Epoch: 993 Train loss: 0.3762462\n",
      "Epoch: 994 Train loss: 0.3760958\n",
      "Epoch: 995 Train loss: 0.3759450\n",
      "Epoch: 996 Train loss: 0.3757938\n",
      "Epoch: 997 Train loss: 0.3756424\n",
      "Epoch: 998 Train loss: 0.3754908\n",
      "Epoch: 999 Train loss: 0.3753397\n",
      "Epoch: 1000 Train loss: 0.3751886\n",
      "Epoch: 1001 Train loss: 0.3750379\n",
      "Epoch: 1002 Train loss: 0.3748876\n",
      "Epoch: 1003 Train loss: 0.3747379\n",
      "Epoch: 1004 Train loss: 0.3745891\n",
      "Epoch: 1005 Train loss: 0.3744409\n",
      "Epoch: 1006 Train loss: 0.3742937\n",
      "Epoch: 1007 Train loss: 0.3741472\n",
      "Epoch: 1008 Train loss: 0.3740017\n",
      "Epoch: 1009 Train loss: 0.3738571\n",
      "Epoch: 1010 Train loss: 0.3737136\n",
      "Epoch: 1011 Train loss: 0.3735711\n",
      "Epoch: 1012 Train loss: 0.3734293\n",
      "Epoch: 1013 Train loss: 0.3732886\n",
      "Epoch: 1014 Train loss: 0.3731488\n",
      "Epoch: 1015 Train loss: 0.3730098\n",
      "Epoch: 1016 Train loss: 0.3728718\n",
      "Epoch: 1017 Train loss: 0.3727345\n",
      "Epoch: 1018 Train loss: 0.3725982\n",
      "Epoch: 1019 Train loss: 0.3724627\n",
      "Epoch: 1020 Train loss: 0.3723279\n",
      "Epoch: 1021 Train loss: 0.3721938\n",
      "Epoch: 1022 Train loss: 0.3720603\n",
      "Epoch: 1023 Train loss: 0.3719274\n",
      "Epoch: 1024 Train loss: 0.3717951\n",
      "Epoch: 1025 Train loss: 0.3716634\n",
      "Epoch: 1026 Train loss: 0.3715322\n",
      "Epoch: 1027 Train loss: 0.3714015\n",
      "Epoch: 1028 Train loss: 0.3712714\n",
      "Epoch: 1029 Train loss: 0.3711415\n",
      "Epoch: 1030 Train loss: 0.3710121\n",
      "Epoch: 1031 Train loss: 0.3708831\n",
      "Epoch: 1032 Train loss: 0.3707545\n",
      "Epoch: 1033 Train loss: 0.3706261\n",
      "Epoch: 1034 Train loss: 0.3704980\n",
      "Epoch: 1035 Train loss: 0.3703703\n",
      "Epoch: 1036 Train loss: 0.3702427\n",
      "Epoch: 1037 Train loss: 0.3701156\n",
      "Epoch: 1038 Train loss: 0.3699887\n",
      "Epoch: 1039 Train loss: 0.3698621\n",
      "Epoch: 1040 Train loss: 0.3697359\n",
      "Epoch: 1041 Train loss: 0.3696098\n",
      "Epoch: 1042 Train loss: 0.3694840\n",
      "Epoch: 1043 Train loss: 0.3693589\n",
      "Epoch: 1044 Train loss: 0.3692339\n",
      "Epoch: 1045 Train loss: 0.3691092\n",
      "Epoch: 1046 Train loss: 0.3689852\n",
      "Epoch: 1047 Train loss: 0.3688615\n",
      "Epoch: 1048 Train loss: 0.3687383\n",
      "Epoch: 1049 Train loss: 0.3686156\n",
      "Epoch: 1050 Train loss: 0.3684934\n",
      "Epoch: 1051 Train loss: 0.3683719\n",
      "Epoch: 1052 Train loss: 0.3682509\n",
      "Epoch: 1053 Train loss: 0.3681305\n",
      "Epoch: 1054 Train loss: 0.3680109\n",
      "Epoch: 1055 Train loss: 0.3678918\n",
      "Epoch: 1056 Train loss: 0.3677736\n",
      "Epoch: 1057 Train loss: 0.3676562\n",
      "Epoch: 1058 Train loss: 0.3675393\n",
      "Epoch: 1059 Train loss: 0.3674231\n",
      "Epoch: 1060 Train loss: 0.3673078\n",
      "Epoch: 1061 Train loss: 0.3671932\n",
      "Epoch: 1062 Train loss: 0.3670794\n",
      "Epoch: 1063 Train loss: 0.3669666\n",
      "Epoch: 1064 Train loss: 0.3668543\n",
      "Epoch: 1065 Train loss: 0.3667429\n",
      "Epoch: 1066 Train loss: 0.3666323\n",
      "Epoch: 1067 Train loss: 0.3665226\n",
      "Epoch: 1068 Train loss: 0.3664136\n",
      "Epoch: 1069 Train loss: 0.3663053\n",
      "Epoch: 1070 Train loss: 0.3661979\n",
      "Epoch: 1071 Train loss: 0.3660914\n",
      "Epoch: 1072 Train loss: 0.3659856\n",
      "Epoch: 1073 Train loss: 0.3658807\n",
      "Epoch: 1074 Train loss: 0.3657763\n",
      "Epoch: 1075 Train loss: 0.3656729\n",
      "Epoch: 1076 Train loss: 0.3655702\n",
      "Epoch: 1077 Train loss: 0.3654681\n",
      "Epoch: 1078 Train loss: 0.3653669\n",
      "Epoch: 1079 Train loss: 0.3652664\n",
      "Epoch: 1080 Train loss: 0.3651665\n",
      "Epoch: 1081 Train loss: 0.3650674\n",
      "Epoch: 1082 Train loss: 0.3649689\n",
      "Epoch: 1083 Train loss: 0.3648708\n",
      "Epoch: 1084 Train loss: 0.3647736\n",
      "Epoch: 1085 Train loss: 0.3646768\n",
      "Epoch: 1086 Train loss: 0.3645806\n",
      "Epoch: 1087 Train loss: 0.3644851\n",
      "Epoch: 1088 Train loss: 0.3643900\n",
      "Epoch: 1089 Train loss: 0.3642954\n",
      "Epoch: 1090 Train loss: 0.3642013\n",
      "Epoch: 1091 Train loss: 0.3641076\n",
      "Epoch: 1092 Train loss: 0.3640144\n",
      "Epoch: 1093 Train loss: 0.3639216\n",
      "Epoch: 1094 Train loss: 0.3638294\n",
      "Epoch: 1095 Train loss: 0.3637374\n",
      "Epoch: 1096 Train loss: 0.3636459\n",
      "Epoch: 1097 Train loss: 0.3635547\n",
      "Epoch: 1098 Train loss: 0.3634639\n",
      "Epoch: 1099 Train loss: 0.3633734\n",
      "Epoch: 1100 Train loss: 0.3632832\n",
      "Epoch: 1101 Train loss: 0.3631934\n",
      "Epoch: 1102 Train loss: 0.3631039\n",
      "Epoch: 1103 Train loss: 0.3630146\n",
      "Epoch: 1104 Train loss: 0.3629259\n",
      "Epoch: 1105 Train loss: 0.3628373\n",
      "Epoch: 1106 Train loss: 0.3627491\n",
      "Epoch: 1107 Train loss: 0.3626612\n",
      "Epoch: 1108 Train loss: 0.3625735\n",
      "Epoch: 1109 Train loss: 0.3624860\n",
      "Epoch: 1110 Train loss: 0.3623990\n",
      "Epoch: 1111 Train loss: 0.3623122\n",
      "Epoch: 1112 Train loss: 0.3622257\n",
      "Epoch: 1113 Train loss: 0.3621396\n",
      "Epoch: 1114 Train loss: 0.3620537\n",
      "Epoch: 1115 Train loss: 0.3619680\n",
      "Epoch: 1116 Train loss: 0.3618828\n",
      "Epoch: 1117 Train loss: 0.3617980\n",
      "Epoch: 1118 Train loss: 0.3617135\n",
      "Epoch: 1119 Train loss: 0.3616295\n",
      "Epoch: 1120 Train loss: 0.3615455\n",
      "Epoch: 1121 Train loss: 0.3614620\n",
      "Epoch: 1122 Train loss: 0.3613790\n",
      "Epoch: 1123 Train loss: 0.3612963\n",
      "Epoch: 1124 Train loss: 0.3612142\n",
      "Epoch: 1125 Train loss: 0.3611322\n",
      "Epoch: 1126 Train loss: 0.3610507\n",
      "Epoch: 1127 Train loss: 0.3609697\n",
      "Epoch: 1128 Train loss: 0.3608890\n",
      "Epoch: 1129 Train loss: 0.3608088\n",
      "Epoch: 1130 Train loss: 0.3607291\n",
      "Epoch: 1131 Train loss: 0.3606497\n",
      "Epoch: 1132 Train loss: 0.3605706\n",
      "Epoch: 1133 Train loss: 0.3604919\n",
      "Epoch: 1134 Train loss: 0.3604138\n",
      "Epoch: 1135 Train loss: 0.3603361\n",
      "Epoch: 1136 Train loss: 0.3602585\n",
      "Epoch: 1137 Train loss: 0.3601815\n",
      "Epoch: 1138 Train loss: 0.3601050\n",
      "Epoch: 1139 Train loss: 0.3600287\n",
      "Epoch: 1140 Train loss: 0.3599527\n",
      "Epoch: 1141 Train loss: 0.3598772\n",
      "Epoch: 1142 Train loss: 0.3598020\n",
      "Epoch: 1143 Train loss: 0.3597272\n",
      "Epoch: 1144 Train loss: 0.3596526\n",
      "Epoch: 1145 Train loss: 0.3595785\n",
      "Epoch: 1146 Train loss: 0.3595046\n",
      "Epoch: 1147 Train loss: 0.3594310\n",
      "Epoch: 1148 Train loss: 0.3593578\n",
      "Epoch: 1149 Train loss: 0.3592849\n",
      "Epoch: 1150 Train loss: 0.3592124\n",
      "Epoch: 1151 Train loss: 0.3591401\n",
      "Epoch: 1152 Train loss: 0.3590680\n",
      "Epoch: 1153 Train loss: 0.3589963\n",
      "Epoch: 1154 Train loss: 0.3589247\n",
      "Epoch: 1155 Train loss: 0.3588537\n",
      "Epoch: 1156 Train loss: 0.3587828\n",
      "Epoch: 1157 Train loss: 0.3587122\n",
      "Epoch: 1158 Train loss: 0.3586418\n",
      "Epoch: 1159 Train loss: 0.3585718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1160 Train loss: 0.3585020\n",
      "Epoch: 1161 Train loss: 0.3584325\n",
      "Epoch: 1162 Train loss: 0.3583633\n",
      "Epoch: 1163 Train loss: 0.3582944\n",
      "Epoch: 1164 Train loss: 0.3582257\n",
      "Epoch: 1165 Train loss: 0.3581573\n",
      "Epoch: 1166 Train loss: 0.3580891\n",
      "Epoch: 1167 Train loss: 0.3580211\n",
      "Epoch: 1168 Train loss: 0.3579534\n",
      "Epoch: 1169 Train loss: 0.3578857\n",
      "Epoch: 1170 Train loss: 0.3578186\n",
      "Epoch: 1171 Train loss: 0.3577516\n",
      "Epoch: 1172 Train loss: 0.3576849\n",
      "Epoch: 1173 Train loss: 0.3576184\n",
      "Epoch: 1174 Train loss: 0.3575522\n",
      "Epoch: 1175 Train loss: 0.3574862\n",
      "Epoch: 1176 Train loss: 0.3574204\n",
      "Epoch: 1177 Train loss: 0.3573549\n",
      "Epoch: 1178 Train loss: 0.3572897\n",
      "Epoch: 1179 Train loss: 0.3572246\n",
      "Epoch: 1180 Train loss: 0.3571597\n",
      "Epoch: 1181 Train loss: 0.3570951\n",
      "Epoch: 1182 Train loss: 0.3570306\n",
      "Epoch: 1183 Train loss: 0.3569664\n",
      "Epoch: 1184 Train loss: 0.3569024\n",
      "Epoch: 1185 Train loss: 0.3568386\n",
      "Epoch: 1186 Train loss: 0.3567751\n",
      "Epoch: 1187 Train loss: 0.3567118\n",
      "Epoch: 1188 Train loss: 0.3566487\n",
      "Epoch: 1189 Train loss: 0.3565859\n",
      "Epoch: 1190 Train loss: 0.3565233\n",
      "Epoch: 1191 Train loss: 0.3564608\n",
      "Epoch: 1192 Train loss: 0.3563985\n",
      "Epoch: 1193 Train loss: 0.3563364\n",
      "Epoch: 1194 Train loss: 0.3562745\n",
      "Epoch: 1195 Train loss: 0.3562129\n",
      "Epoch: 1196 Train loss: 0.3561514\n",
      "Epoch: 1197 Train loss: 0.3560899\n",
      "Epoch: 1198 Train loss: 0.3560288\n",
      "Epoch: 1199 Train loss: 0.3559679\n",
      "Epoch: 1200 Train loss: 0.3559071\n",
      "Epoch: 1201 Train loss: 0.3558465\n",
      "Epoch: 1202 Train loss: 0.3557863\n",
      "Epoch: 1203 Train loss: 0.3557260\n",
      "Epoch: 1204 Train loss: 0.3556659\n",
      "Epoch: 1205 Train loss: 0.3556059\n",
      "Epoch: 1206 Train loss: 0.3555461\n",
      "Epoch: 1207 Train loss: 0.3554866\n",
      "Epoch: 1208 Train loss: 0.3554271\n",
      "Epoch: 1209 Train loss: 0.3553677\n",
      "Epoch: 1210 Train loss: 0.3553084\n",
      "Epoch: 1211 Train loss: 0.3552493\n",
      "Epoch: 1212 Train loss: 0.3551902\n",
      "Epoch: 1213 Train loss: 0.3551315\n",
      "Epoch: 1214 Train loss: 0.3550728\n",
      "Epoch: 1215 Train loss: 0.3550142\n",
      "Epoch: 1216 Train loss: 0.3549555\n",
      "Epoch: 1217 Train loss: 0.3548970\n",
      "Epoch: 1218 Train loss: 0.3548385\n",
      "Epoch: 1219 Train loss: 0.3547800\n",
      "Epoch: 1220 Train loss: 0.3547217\n",
      "Epoch: 1221 Train loss: 0.3546635\n",
      "Epoch: 1222 Train loss: 0.3546050\n",
      "Epoch: 1223 Train loss: 0.3545468\n",
      "Epoch: 1224 Train loss: 0.3544884\n",
      "Epoch: 1225 Train loss: 0.3544299\n",
      "Epoch: 1226 Train loss: 0.3543716\n",
      "Epoch: 1227 Train loss: 0.3543129\n",
      "Epoch: 1228 Train loss: 0.3542543\n",
      "Epoch: 1229 Train loss: 0.3541955\n",
      "Epoch: 1230 Train loss: 0.3541367\n",
      "Epoch: 1231 Train loss: 0.3540777\n",
      "Epoch: 1232 Train loss: 0.3540184\n",
      "Epoch: 1233 Train loss: 0.3539591\n",
      "Epoch: 1234 Train loss: 0.3538994\n",
      "Epoch: 1235 Train loss: 0.3538394\n",
      "Epoch: 1236 Train loss: 0.3537793\n",
      "Epoch: 1237 Train loss: 0.3537188\n",
      "Epoch: 1238 Train loss: 0.3536581\n",
      "Epoch: 1239 Train loss: 0.3535970\n",
      "Epoch: 1240 Train loss: 0.3535359\n",
      "Epoch: 1241 Train loss: 0.3534746\n",
      "Epoch: 1242 Train loss: 0.3534128\n",
      "Epoch: 1243 Train loss: 0.3533511\n",
      "Epoch: 1244 Train loss: 0.3532890\n",
      "Epoch: 1245 Train loss: 0.3532268\n",
      "Epoch: 1246 Train loss: 0.3531645\n",
      "Epoch: 1247 Train loss: 0.3531021\n",
      "Epoch: 1248 Train loss: 0.3530397\n",
      "Epoch: 1249 Train loss: 0.3529773\n",
      "Epoch: 1250 Train loss: 0.3529148\n",
      "Epoch: 1251 Train loss: 0.3528524\n",
      "Epoch: 1252 Train loss: 0.3527898\n",
      "Epoch: 1253 Train loss: 0.3527274\n",
      "Epoch: 1254 Train loss: 0.3526651\n",
      "Epoch: 1255 Train loss: 0.3526028\n",
      "Epoch: 1256 Train loss: 0.3525406\n",
      "Epoch: 1257 Train loss: 0.3524785\n",
      "Epoch: 1258 Train loss: 0.3524166\n",
      "Epoch: 1259 Train loss: 0.3523546\n",
      "Epoch: 1260 Train loss: 0.3522928\n",
      "Epoch: 1261 Train loss: 0.3522310\n",
      "Epoch: 1262 Train loss: 0.3521693\n",
      "Epoch: 1263 Train loss: 0.3521075\n",
      "Epoch: 1264 Train loss: 0.3520459\n",
      "Epoch: 1265 Train loss: 0.3519843\n",
      "Epoch: 1266 Train loss: 0.3519229\n",
      "Epoch: 1267 Train loss: 0.3518616\n",
      "Epoch: 1268 Train loss: 0.3518002\n",
      "Epoch: 1269 Train loss: 0.3517392\n",
      "Epoch: 1270 Train loss: 0.3516781\n",
      "Epoch: 1271 Train loss: 0.3516172\n",
      "Epoch: 1272 Train loss: 0.3515565\n",
      "Epoch: 1273 Train loss: 0.3514958\n",
      "Epoch: 1274 Train loss: 0.3514354\n",
      "Epoch: 1275 Train loss: 0.3513749\n",
      "Epoch: 1276 Train loss: 0.3513150\n",
      "Epoch: 1277 Train loss: 0.3512550\n",
      "Epoch: 1278 Train loss: 0.3511952\n",
      "Epoch: 1279 Train loss: 0.3511356\n",
      "Epoch: 1280 Train loss: 0.3510761\n",
      "Epoch: 1281 Train loss: 0.3510167\n",
      "Epoch: 1282 Train loss: 0.3509577\n",
      "Epoch: 1283 Train loss: 0.3508984\n",
      "Epoch: 1284 Train loss: 0.3508394\n",
      "Epoch: 1285 Train loss: 0.3507804\n",
      "Epoch: 1286 Train loss: 0.3507217\n",
      "Epoch: 1287 Train loss: 0.3506630\n",
      "Epoch: 1288 Train loss: 0.3506044\n",
      "Epoch: 1289 Train loss: 0.3505459\n",
      "Epoch: 1290 Train loss: 0.3504874\n",
      "Epoch: 1291 Train loss: 0.3504291\n",
      "Epoch: 1292 Train loss: 0.3503706\n",
      "Epoch: 1293 Train loss: 0.3503121\n",
      "Epoch: 1294 Train loss: 0.3502536\n",
      "Epoch: 1295 Train loss: 0.3501952\n",
      "Epoch: 1296 Train loss: 0.3501367\n",
      "Epoch: 1297 Train loss: 0.3500781\n",
      "Epoch: 1298 Train loss: 0.3500196\n",
      "Epoch: 1299 Train loss: 0.3499610\n",
      "Epoch: 1300 Train loss: 0.3499023\n",
      "Epoch: 1301 Train loss: 0.3498435\n",
      "Epoch: 1302 Train loss: 0.3497845\n",
      "Epoch: 1303 Train loss: 0.3497257\n",
      "Epoch: 1304 Train loss: 0.3496667\n",
      "Epoch: 1305 Train loss: 0.3496077\n",
      "Epoch: 1306 Train loss: 0.3495485\n",
      "Epoch: 1307 Train loss: 0.3494895\n",
      "Epoch: 1308 Train loss: 0.3494305\n",
      "Epoch: 1309 Train loss: 0.3493714\n",
      "Epoch: 1310 Train loss: 0.3493125\n",
      "Epoch: 1311 Train loss: 0.3492536\n",
      "Epoch: 1312 Train loss: 0.3491948\n",
      "Epoch: 1313 Train loss: 0.3491361\n",
      "Epoch: 1314 Train loss: 0.3490775\n",
      "Epoch: 1315 Train loss: 0.3490191\n",
      "Epoch: 1316 Train loss: 0.3489608\n",
      "Epoch: 1317 Train loss: 0.3489027\n",
      "Epoch: 1318 Train loss: 0.3488449\n",
      "Epoch: 1319 Train loss: 0.3487871\n",
      "Epoch: 1320 Train loss: 0.3487297\n",
      "Epoch: 1321 Train loss: 0.3486726\n",
      "Epoch: 1322 Train loss: 0.3486155\n",
      "Epoch: 1323 Train loss: 0.3485586\n",
      "Epoch: 1324 Train loss: 0.3485021\n",
      "Epoch: 1325 Train loss: 0.3484456\n",
      "Epoch: 1326 Train loss: 0.3483892\n",
      "Epoch: 1327 Train loss: 0.3483332\n",
      "Epoch: 1328 Train loss: 0.3482774\n",
      "Epoch: 1329 Train loss: 0.3482217\n",
      "Epoch: 1330 Train loss: 0.3481661\n",
      "Epoch: 1331 Train loss: 0.3481107\n",
      "Epoch: 1332 Train loss: 0.3480557\n",
      "Epoch: 1333 Train loss: 0.3480006\n",
      "Epoch: 1334 Train loss: 0.3479456\n",
      "Epoch: 1335 Train loss: 0.3478908\n",
      "Epoch: 1336 Train loss: 0.3478362\n",
      "Epoch: 1337 Train loss: 0.3477816\n",
      "Epoch: 1338 Train loss: 0.3477272\n",
      "Epoch: 1339 Train loss: 0.3476731\n",
      "Epoch: 1340 Train loss: 0.3476191\n",
      "Epoch: 1341 Train loss: 0.3475652\n",
      "Epoch: 1342 Train loss: 0.3475114\n",
      "Epoch: 1343 Train loss: 0.3474578\n",
      "Epoch: 1344 Train loss: 0.3474042\n",
      "Epoch: 1345 Train loss: 0.3473510\n",
      "Epoch: 1346 Train loss: 0.3472978\n",
      "Epoch: 1347 Train loss: 0.3472449\n",
      "Epoch: 1348 Train loss: 0.3471921\n",
      "Epoch: 1349 Train loss: 0.3471393\n",
      "Epoch: 1350 Train loss: 0.3470868\n",
      "Epoch: 1351 Train loss: 0.3470344\n",
      "Epoch: 1352 Train loss: 0.3469821\n",
      "Epoch: 1353 Train loss: 0.3469301\n",
      "Epoch: 1354 Train loss: 0.3468781\n",
      "Epoch: 1355 Train loss: 0.3468262\n",
      "Epoch: 1356 Train loss: 0.3467745\n",
      "Epoch: 1357 Train loss: 0.3467231\n",
      "Epoch: 1358 Train loss: 0.3466715\n",
      "Epoch: 1359 Train loss: 0.3466202\n",
      "Epoch: 1360 Train loss: 0.3465688\n",
      "Epoch: 1361 Train loss: 0.3465176\n",
      "Epoch: 1362 Train loss: 0.3464665\n",
      "Epoch: 1363 Train loss: 0.3464154\n",
      "Epoch: 1364 Train loss: 0.3463644\n",
      "Epoch: 1365 Train loss: 0.3463135\n",
      "Epoch: 1366 Train loss: 0.3462626\n",
      "Epoch: 1367 Train loss: 0.3462118\n",
      "Epoch: 1368 Train loss: 0.3461611\n",
      "Epoch: 1369 Train loss: 0.3461104\n",
      "Epoch: 1370 Train loss: 0.3460597\n",
      "Epoch: 1371 Train loss: 0.3460089\n",
      "Epoch: 1372 Train loss: 0.3459584\n",
      "Epoch: 1373 Train loss: 0.3459079\n",
      "Epoch: 1374 Train loss: 0.3458575\n",
      "Epoch: 1375 Train loss: 0.3458074\n",
      "Epoch: 1376 Train loss: 0.3457574\n",
      "Epoch: 1377 Train loss: 0.3457074\n",
      "Epoch: 1378 Train loss: 0.3456580\n",
      "Epoch: 1379 Train loss: 0.3456085\n",
      "Epoch: 1380 Train loss: 0.3455594\n",
      "Epoch: 1381 Train loss: 0.3455105\n",
      "Epoch: 1382 Train loss: 0.3454618\n",
      "Epoch: 1383 Train loss: 0.3454137\n",
      "Epoch: 1384 Train loss: 0.3453658\n",
      "Epoch: 1385 Train loss: 0.3453181\n",
      "Epoch: 1386 Train loss: 0.3452710\n",
      "Epoch: 1387 Train loss: 0.3452241\n",
      "Epoch: 1388 Train loss: 0.3451777\n",
      "Epoch: 1389 Train loss: 0.3451316\n",
      "Epoch: 1390 Train loss: 0.3450859\n",
      "Epoch: 1391 Train loss: 0.3450406\n",
      "Epoch: 1392 Train loss: 0.3449956\n",
      "Epoch: 1393 Train loss: 0.3449509\n",
      "Epoch: 1394 Train loss: 0.3449067\n",
      "Epoch: 1395 Train loss: 0.3448627\n",
      "Epoch: 1396 Train loss: 0.3448189\n",
      "Epoch: 1397 Train loss: 0.3447753\n",
      "Epoch: 1398 Train loss: 0.3447318\n",
      "Epoch: 1399 Train loss: 0.3446884\n",
      "Epoch: 1400 Train loss: 0.3446452\n",
      "Epoch: 1401 Train loss: 0.3446021\n",
      "Epoch: 1402 Train loss: 0.3445592\n",
      "Epoch: 1403 Train loss: 0.3445164\n",
      "Epoch: 1404 Train loss: 0.3444737\n",
      "Epoch: 1405 Train loss: 0.3444310\n",
      "Epoch: 1406 Train loss: 0.3443884\n",
      "Epoch: 1407 Train loss: 0.3443459\n",
      "Epoch: 1408 Train loss: 0.3443035\n",
      "Epoch: 1409 Train loss: 0.3442612\n",
      "Epoch: 1410 Train loss: 0.3442189\n",
      "Epoch: 1411 Train loss: 0.3441768\n",
      "Epoch: 1412 Train loss: 0.3441346\n",
      "Epoch: 1413 Train loss: 0.3440927\n",
      "Epoch: 1414 Train loss: 0.3440509\n",
      "Epoch: 1415 Train loss: 0.3440095\n",
      "Epoch: 1416 Train loss: 0.3439679\n",
      "Epoch: 1417 Train loss: 0.3439268\n",
      "Epoch: 1418 Train loss: 0.3438858\n",
      "Epoch: 1419 Train loss: 0.3438450\n",
      "Epoch: 1420 Train loss: 0.3438045\n",
      "Epoch: 1421 Train loss: 0.3437642\n",
      "Epoch: 1422 Train loss: 0.3437240\n",
      "Epoch: 1423 Train loss: 0.3436842\n",
      "Epoch: 1424 Train loss: 0.3436444\n",
      "Epoch: 1425 Train loss: 0.3436049\n",
      "Epoch: 1426 Train loss: 0.3435655\n",
      "Epoch: 1427 Train loss: 0.3435264\n",
      "Epoch: 1428 Train loss: 0.3434876\n",
      "Epoch: 1429 Train loss: 0.3434490\n",
      "Epoch: 1430 Train loss: 0.3434106\n",
      "Epoch: 1431 Train loss: 0.3433723\n",
      "Epoch: 1432 Train loss: 0.3433340\n",
      "Epoch: 1433 Train loss: 0.3432963\n",
      "Epoch: 1434 Train loss: 0.3432587\n",
      "Epoch: 1435 Train loss: 0.3432213\n",
      "Epoch: 1436 Train loss: 0.3431841\n",
      "Epoch: 1437 Train loss: 0.3431471\n",
      "Epoch: 1438 Train loss: 0.3431101\n",
      "Epoch: 1439 Train loss: 0.3430733\n",
      "Epoch: 1440 Train loss: 0.3430367\n",
      "Epoch: 1441 Train loss: 0.3430002\n",
      "Epoch: 1442 Train loss: 0.3429639\n",
      "Epoch: 1443 Train loss: 0.3429276\n",
      "Epoch: 1444 Train loss: 0.3428915\n",
      "Epoch: 1445 Train loss: 0.3428554\n",
      "Epoch: 1446 Train loss: 0.3428192\n",
      "Epoch: 1447 Train loss: 0.3427833\n",
      "Epoch: 1448 Train loss: 0.3427474\n",
      "Epoch: 1449 Train loss: 0.3427115\n",
      "Epoch: 1450 Train loss: 0.3426755\n",
      "Epoch: 1451 Train loss: 0.3426396\n",
      "Epoch: 1452 Train loss: 0.3426035\n",
      "Epoch: 1453 Train loss: 0.3425675\n",
      "Epoch: 1454 Train loss: 0.3425314\n",
      "Epoch: 1455 Train loss: 0.3424953\n",
      "Epoch: 1456 Train loss: 0.3424592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1457 Train loss: 0.3424232\n",
      "Epoch: 1458 Train loss: 0.3423873\n",
      "Epoch: 1459 Train loss: 0.3423512\n",
      "Epoch: 1460 Train loss: 0.3423151\n",
      "Epoch: 1461 Train loss: 0.3422790\n",
      "Epoch: 1462 Train loss: 0.3422430\n",
      "Epoch: 1463 Train loss: 0.3422070\n",
      "Epoch: 1464 Train loss: 0.3421709\n",
      "Epoch: 1465 Train loss: 0.3421345\n",
      "Epoch: 1466 Train loss: 0.3420981\n",
      "Epoch: 1467 Train loss: 0.3420614\n",
      "Epoch: 1468 Train loss: 0.3420246\n",
      "Epoch: 1469 Train loss: 0.3419875\n",
      "Epoch: 1470 Train loss: 0.3419500\n",
      "Epoch: 1471 Train loss: 0.3419123\n",
      "Epoch: 1472 Train loss: 0.3418742\n",
      "Epoch: 1473 Train loss: 0.3418356\n",
      "Epoch: 1474 Train loss: 0.3417968\n",
      "Epoch: 1475 Train loss: 0.3417577\n",
      "Epoch: 1476 Train loss: 0.3417182\n",
      "Epoch: 1477 Train loss: 0.3416787\n",
      "Epoch: 1478 Train loss: 0.3416389\n",
      "Epoch: 1479 Train loss: 0.3415993\n",
      "Epoch: 1480 Train loss: 0.3415599\n",
      "Epoch: 1481 Train loss: 0.3415207\n",
      "Epoch: 1482 Train loss: 0.3414819\n",
      "Epoch: 1483 Train loss: 0.3414434\n",
      "Epoch: 1484 Train loss: 0.3414054\n",
      "Epoch: 1485 Train loss: 0.3413679\n",
      "Epoch: 1486 Train loss: 0.3413310\n",
      "Epoch: 1487 Train loss: 0.3412947\n",
      "Epoch: 1488 Train loss: 0.3412587\n",
      "Epoch: 1489 Train loss: 0.3412234\n",
      "Epoch: 1490 Train loss: 0.3411886\n",
      "Epoch: 1491 Train loss: 0.3411543\n",
      "Epoch: 1492 Train loss: 0.3411205\n",
      "Epoch: 1493 Train loss: 0.3410871\n",
      "Epoch: 1494 Train loss: 0.3410541\n",
      "Epoch: 1495 Train loss: 0.3410217\n",
      "Epoch: 1496 Train loss: 0.3409895\n",
      "Epoch: 1497 Train loss: 0.3409578\n",
      "Epoch: 1498 Train loss: 0.3409263\n",
      "Epoch: 1499 Train loss: 0.3408952\n",
      "Epoch: 1500 Train loss: 0.3408645\n",
      "Epoch: 1501 Train loss: 0.3408341\n",
      "Epoch: 1502 Train loss: 0.3408041\n",
      "Epoch: 1503 Train loss: 0.3407746\n",
      "Epoch: 1504 Train loss: 0.3407459\n",
      "Epoch: 1505 Train loss: 0.3407176\n",
      "Epoch: 1506 Train loss: 0.3406900\n",
      "Epoch: 1507 Train loss: 0.3406625\n",
      "Epoch: 1508 Train loss: 0.3406346\n",
      "Epoch: 1509 Train loss: 0.3406051\n",
      "Epoch: 1510 Train loss: 0.3405748\n",
      "Epoch: 1511 Train loss: 0.3405449\n",
      "Epoch: 1512 Train loss: 0.3405167\n",
      "Epoch: 1513 Train loss: 0.3404905\n",
      "Epoch: 1514 Train loss: 0.3404644\n",
      "Epoch: 1515 Train loss: 0.3404375\n",
      "Epoch: 1516 Train loss: 0.3404096\n",
      "Epoch: 1517 Train loss: 0.3403818\n",
      "Epoch: 1518 Train loss: 0.3403551\n",
      "Epoch: 1519 Train loss: 0.3403295\n",
      "Epoch: 1520 Train loss: 0.3403040\n",
      "Epoch: 1521 Train loss: 0.3402777\n",
      "Epoch: 1522 Train loss: 0.3402512\n",
      "Epoch: 1523 Train loss: 0.3402250\n",
      "Epoch: 1524 Train loss: 0.3401997\n",
      "Epoch: 1525 Train loss: 0.3401746\n",
      "Epoch: 1526 Train loss: 0.3401492\n",
      "Epoch: 1527 Train loss: 0.3401235\n",
      "Epoch: 1528 Train loss: 0.3400982\n",
      "Epoch: 1529 Train loss: 0.3400735\n",
      "Epoch: 1530 Train loss: 0.3400489\n",
      "Epoch: 1531 Train loss: 0.3400241\n",
      "Epoch: 1532 Train loss: 0.3399992\n",
      "Epoch: 1533 Train loss: 0.3399745\n",
      "Epoch: 1534 Train loss: 0.3399503\n",
      "Epoch: 1535 Train loss: 0.3399262\n",
      "Epoch: 1536 Train loss: 0.3399019\n",
      "Epoch: 1537 Train loss: 0.3398777\n",
      "Epoch: 1538 Train loss: 0.3398537\n",
      "Epoch: 1539 Train loss: 0.3398299\n",
      "Epoch: 1540 Train loss: 0.3398063\n",
      "Epoch: 1541 Train loss: 0.3397826\n",
      "Epoch: 1542 Train loss: 0.3397590\n",
      "Epoch: 1543 Train loss: 0.3397356\n",
      "Epoch: 1544 Train loss: 0.3397123\n",
      "Epoch: 1545 Train loss: 0.3396891\n",
      "Epoch: 1546 Train loss: 0.3396659\n",
      "Epoch: 1547 Train loss: 0.3396429\n",
      "Epoch: 1548 Train loss: 0.3396199\n",
      "Epoch: 1549 Train loss: 0.3395970\n",
      "Epoch: 1550 Train loss: 0.3395742\n",
      "Epoch: 1551 Train loss: 0.3395515\n",
      "Epoch: 1552 Train loss: 0.3395288\n",
      "Epoch: 1553 Train loss: 0.3395062\n",
      "Epoch: 1554 Train loss: 0.3394838\n",
      "Epoch: 1555 Train loss: 0.3394615\n",
      "Epoch: 1556 Train loss: 0.3394392\n",
      "Epoch: 1557 Train loss: 0.3394171\n",
      "Epoch: 1558 Train loss: 0.3393951\n",
      "Epoch: 1559 Train loss: 0.3393731\n",
      "Epoch: 1560 Train loss: 0.3393511\n",
      "Epoch: 1561 Train loss: 0.3393294\n",
      "Epoch: 1562 Train loss: 0.3393075\n",
      "Epoch: 1563 Train loss: 0.3392859\n",
      "Epoch: 1564 Train loss: 0.3392642\n",
      "Epoch: 1565 Train loss: 0.3392428\n",
      "Epoch: 1566 Train loss: 0.3392212\n",
      "Epoch: 1567 Train loss: 0.3391998\n",
      "Epoch: 1568 Train loss: 0.3391785\n",
      "Epoch: 1569 Train loss: 0.3391574\n",
      "Epoch: 1570 Train loss: 0.3391361\n",
      "Epoch: 1571 Train loss: 0.3391152\n",
      "Epoch: 1572 Train loss: 0.3390943\n",
      "Epoch: 1573 Train loss: 0.3390733\n",
      "Epoch: 1574 Train loss: 0.3390525\n",
      "Epoch: 1575 Train loss: 0.3390317\n",
      "Epoch: 1576 Train loss: 0.3390111\n",
      "Epoch: 1577 Train loss: 0.3389905\n",
      "Epoch: 1578 Train loss: 0.3389700\n",
      "Epoch: 1579 Train loss: 0.3389496\n",
      "Epoch: 1580 Train loss: 0.3389291\n",
      "Epoch: 1581 Train loss: 0.3389087\n",
      "Epoch: 1582 Train loss: 0.3388884\n",
      "Epoch: 1583 Train loss: 0.3388683\n",
      "Epoch: 1584 Train loss: 0.3388480\n",
      "Epoch: 1585 Train loss: 0.3388279\n",
      "Epoch: 1586 Train loss: 0.3388080\n",
      "Epoch: 1587 Train loss: 0.3387881\n",
      "Epoch: 1588 Train loss: 0.3387683\n",
      "Epoch: 1589 Train loss: 0.3387484\n",
      "Epoch: 1590 Train loss: 0.3387287\n",
      "Epoch: 1591 Train loss: 0.3387091\n",
      "Epoch: 1592 Train loss: 0.3386895\n",
      "Epoch: 1593 Train loss: 0.3386700\n",
      "Epoch: 1594 Train loss: 0.3386505\n",
      "Epoch: 1595 Train loss: 0.3386311\n",
      "Epoch: 1596 Train loss: 0.3386118\n",
      "Epoch: 1597 Train loss: 0.3385926\n",
      "Epoch: 1598 Train loss: 0.3385735\n",
      "Epoch: 1599 Train loss: 0.3385542\n",
      "Epoch: 1600 Train loss: 0.3385351\n",
      "Epoch: 1601 Train loss: 0.3385161\n",
      "Epoch: 1602 Train loss: 0.3384973\n",
      "Epoch: 1603 Train loss: 0.3384783\n",
      "Epoch: 1604 Train loss: 0.3384593\n",
      "Epoch: 1605 Train loss: 0.3384406\n",
      "Epoch: 1606 Train loss: 0.3384219\n",
      "Epoch: 1607 Train loss: 0.3384033\n",
      "Epoch: 1608 Train loss: 0.3383847\n",
      "Epoch: 1609 Train loss: 0.3383660\n",
      "Epoch: 1610 Train loss: 0.3383474\n",
      "Epoch: 1611 Train loss: 0.3383291\n",
      "Epoch: 1612 Train loss: 0.3383108\n",
      "Epoch: 1613 Train loss: 0.3382925\n",
      "Epoch: 1614 Train loss: 0.3382742\n",
      "Epoch: 1615 Train loss: 0.3382560\n",
      "Epoch: 1616 Train loss: 0.3382379\n",
      "Epoch: 1617 Train loss: 0.3382199\n",
      "Epoch: 1618 Train loss: 0.3382018\n",
      "Epoch: 1619 Train loss: 0.3381838\n",
      "Epoch: 1620 Train loss: 0.3381658\n",
      "Epoch: 1621 Train loss: 0.3381480\n",
      "Epoch: 1622 Train loss: 0.3381302\n",
      "Epoch: 1623 Train loss: 0.3381124\n",
      "Epoch: 1624 Train loss: 0.3380947\n",
      "Epoch: 1625 Train loss: 0.3380771\n",
      "Epoch: 1626 Train loss: 0.3380594\n",
      "Epoch: 1627 Train loss: 0.3380419\n",
      "Epoch: 1628 Train loss: 0.3380244\n",
      "Epoch: 1629 Train loss: 0.3380070\n",
      "Epoch: 1630 Train loss: 0.3379896\n",
      "Epoch: 1631 Train loss: 0.3379723\n",
      "Epoch: 1632 Train loss: 0.3379551\n",
      "Epoch: 1633 Train loss: 0.3379379\n",
      "Epoch: 1634 Train loss: 0.3379206\n",
      "Epoch: 1635 Train loss: 0.3379036\n",
      "Epoch: 1636 Train loss: 0.3378865\n",
      "Epoch: 1637 Train loss: 0.3378695\n",
      "Epoch: 1638 Train loss: 0.3378524\n",
      "Epoch: 1639 Train loss: 0.3378356\n",
      "Epoch: 1640 Train loss: 0.3378185\n",
      "Epoch: 1641 Train loss: 0.3378018\n",
      "Epoch: 1642 Train loss: 0.3377849\n",
      "Epoch: 1643 Train loss: 0.3377682\n",
      "Epoch: 1644 Train loss: 0.3377514\n",
      "Epoch: 1645 Train loss: 0.3377348\n",
      "Epoch: 1646 Train loss: 0.3377182\n",
      "Epoch: 1647 Train loss: 0.3377017\n",
      "Epoch: 1648 Train loss: 0.3376851\n",
      "Epoch: 1649 Train loss: 0.3376687\n",
      "Epoch: 1650 Train loss: 0.3376523\n",
      "Epoch: 1651 Train loss: 0.3376359\n",
      "Epoch: 1652 Train loss: 0.3376197\n",
      "Epoch: 1653 Train loss: 0.3376034\n",
      "Epoch: 1654 Train loss: 0.3375871\n",
      "Epoch: 1655 Train loss: 0.3375709\n",
      "Epoch: 1656 Train loss: 0.3375549\n",
      "Epoch: 1657 Train loss: 0.3375388\n",
      "Epoch: 1658 Train loss: 0.3375228\n",
      "Epoch: 1659 Train loss: 0.3375068\n",
      "Epoch: 1660 Train loss: 0.3374909\n",
      "Epoch: 1661 Train loss: 0.3374748\n",
      "Epoch: 1662 Train loss: 0.3374590\n",
      "Epoch: 1663 Train loss: 0.3374432\n",
      "Epoch: 1664 Train loss: 0.3374274\n",
      "Epoch: 1665 Train loss: 0.3374116\n",
      "Epoch: 1666 Train loss: 0.3373959\n",
      "Epoch: 1667 Train loss: 0.3373803\n",
      "Epoch: 1668 Train loss: 0.3373646\n",
      "Epoch: 1669 Train loss: 0.3373491\n",
      "Epoch: 1670 Train loss: 0.3373336\n",
      "Epoch: 1671 Train loss: 0.3373180\n",
      "Epoch: 1672 Train loss: 0.3373025\n",
      "Epoch: 1673 Train loss: 0.3372871\n",
      "Epoch: 1674 Train loss: 0.3372717\n",
      "Epoch: 1675 Train loss: 0.3372564\n",
      "Epoch: 1676 Train loss: 0.3372410\n",
      "Epoch: 1677 Train loss: 0.3372258\n",
      "Epoch: 1678 Train loss: 0.3372105\n",
      "Epoch: 1679 Train loss: 0.3371955\n",
      "Epoch: 1680 Train loss: 0.3371803\n",
      "Epoch: 1681 Train loss: 0.3371651\n",
      "Epoch: 1682 Train loss: 0.3371501\n",
      "Epoch: 1683 Train loss: 0.3371350\n",
      "Epoch: 1684 Train loss: 0.3371201\n",
      "Epoch: 1685 Train loss: 0.3371051\n",
      "Epoch: 1686 Train loss: 0.3370901\n",
      "Epoch: 1687 Train loss: 0.3370752\n",
      "Epoch: 1688 Train loss: 0.3370604\n",
      "Epoch: 1689 Train loss: 0.3370456\n",
      "Epoch: 1690 Train loss: 0.3370308\n",
      "Epoch: 1691 Train loss: 0.3370160\n",
      "Epoch: 1692 Train loss: 0.3370013\n",
      "Epoch: 1693 Train loss: 0.3369865\n",
      "Epoch: 1694 Train loss: 0.3369718\n",
      "Epoch: 1695 Train loss: 0.3369573\n",
      "Epoch: 1696 Train loss: 0.3369427\n",
      "Epoch: 1697 Train loss: 0.3369281\n",
      "Epoch: 1698 Train loss: 0.3369136\n",
      "Epoch: 1699 Train loss: 0.3368990\n",
      "Epoch: 1700 Train loss: 0.3368845\n",
      "Epoch: 1701 Train loss: 0.3368701\n",
      "Epoch: 1702 Train loss: 0.3368556\n",
      "Epoch: 1703 Train loss: 0.3368412\n",
      "Epoch: 1704 Train loss: 0.3368268\n",
      "Epoch: 1705 Train loss: 0.3368125\n",
      "Epoch: 1706 Train loss: 0.3367981\n",
      "Epoch: 1707 Train loss: 0.3367836\n",
      "Epoch: 1708 Train loss: 0.3367691\n",
      "Epoch: 1709 Train loss: 0.3367546\n",
      "Epoch: 1710 Train loss: 0.3367403\n",
      "Epoch: 1711 Train loss: 0.3367260\n",
      "Epoch: 1712 Train loss: 0.3367116\n",
      "Epoch: 1713 Train loss: 0.3366973\n",
      "Epoch: 1714 Train loss: 0.3366829\n",
      "Epoch: 1715 Train loss: 0.3366686\n",
      "Epoch: 1716 Train loss: 0.3366542\n",
      "Epoch: 1717 Train loss: 0.3366398\n",
      "Epoch: 1718 Train loss: 0.3366252\n",
      "Epoch: 1719 Train loss: 0.3366108\n",
      "Epoch: 1720 Train loss: 0.3365962\n",
      "Epoch: 1721 Train loss: 0.3365816\n",
      "Epoch: 1722 Train loss: 0.3365668\n",
      "Epoch: 1723 Train loss: 0.3365518\n",
      "Epoch: 1724 Train loss: 0.3365368\n",
      "Epoch: 1725 Train loss: 0.3365216\n",
      "Epoch: 1726 Train loss: 0.3365061\n",
      "Epoch: 1727 Train loss: 0.3364904\n",
      "Epoch: 1728 Train loss: 0.3364744\n",
      "Epoch: 1729 Train loss: 0.3364581\n",
      "Epoch: 1730 Train loss: 0.3364413\n",
      "Epoch: 1731 Train loss: 0.3364240\n",
      "Epoch: 1732 Train loss: 0.3364061\n",
      "Epoch: 1733 Train loss: 0.3363878\n",
      "Epoch: 1734 Train loss: 0.3363689\n",
      "Epoch: 1735 Train loss: 0.3363493\n",
      "Epoch: 1736 Train loss: 0.3363296\n",
      "Epoch: 1737 Train loss: 0.3363097\n",
      "Epoch: 1738 Train loss: 0.3362897\n",
      "Epoch: 1739 Train loss: 0.3362700\n",
      "Epoch: 1740 Train loss: 0.3362506\n",
      "Epoch: 1741 Train loss: 0.3362319\n",
      "Epoch: 1742 Train loss: 0.3362137\n",
      "Epoch: 1743 Train loss: 0.3361964\n",
      "Epoch: 1744 Train loss: 0.3361797\n",
      "Epoch: 1745 Train loss: 0.3361638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1746 Train loss: 0.3361483\n",
      "Epoch: 1747 Train loss: 0.3361333\n",
      "Epoch: 1748 Train loss: 0.3361184\n",
      "Epoch: 1749 Train loss: 0.3361038\n",
      "Epoch: 1750 Train loss: 0.3360893\n",
      "Epoch: 1751 Train loss: 0.3360747\n",
      "Epoch: 1752 Train loss: 0.3360601\n",
      "Epoch: 1753 Train loss: 0.3360457\n",
      "Epoch: 1754 Train loss: 0.3360311\n",
      "Epoch: 1755 Train loss: 0.3360166\n",
      "Epoch: 1756 Train loss: 0.3360022\n",
      "Epoch: 1757 Train loss: 0.3359876\n",
      "Epoch: 1758 Train loss: 0.3359733\n",
      "Epoch: 1759 Train loss: 0.3359590\n",
      "Epoch: 1760 Train loss: 0.3359448\n",
      "Epoch: 1761 Train loss: 0.3359308\n",
      "Epoch: 1762 Train loss: 0.3359169\n",
      "Epoch: 1763 Train loss: 0.3359031\n",
      "Epoch: 1764 Train loss: 0.3358894\n",
      "Epoch: 1765 Train loss: 0.3358756\n",
      "Epoch: 1766 Train loss: 0.3358621\n",
      "Epoch: 1767 Train loss: 0.3358488\n",
      "Epoch: 1768 Train loss: 0.3358354\n",
      "Epoch: 1769 Train loss: 0.3358220\n",
      "Epoch: 1770 Train loss: 0.3358088\n",
      "Epoch: 1771 Train loss: 0.3357956\n",
      "Epoch: 1772 Train loss: 0.3357825\n",
      "Epoch: 1773 Train loss: 0.3357693\n",
      "Epoch: 1774 Train loss: 0.3357563\n",
      "Epoch: 1775 Train loss: 0.3357433\n",
      "Epoch: 1776 Train loss: 0.3357304\n",
      "Epoch: 1777 Train loss: 0.3357176\n",
      "Epoch: 1778 Train loss: 0.3357047\n",
      "Epoch: 1779 Train loss: 0.3356919\n",
      "Epoch: 1780 Train loss: 0.3356793\n",
      "Epoch: 1781 Train loss: 0.3356665\n",
      "Epoch: 1782 Train loss: 0.3356538\n",
      "Epoch: 1783 Train loss: 0.3356411\n",
      "Epoch: 1784 Train loss: 0.3356285\n",
      "Epoch: 1785 Train loss: 0.3356160\n",
      "Epoch: 1786 Train loss: 0.3356036\n",
      "Epoch: 1787 Train loss: 0.3355913\n",
      "Epoch: 1788 Train loss: 0.3355789\n",
      "Epoch: 1789 Train loss: 0.3355666\n",
      "Epoch: 1790 Train loss: 0.3355544\n",
      "Epoch: 1791 Train loss: 0.3355422\n",
      "Epoch: 1792 Train loss: 0.3355300\n",
      "Epoch: 1793 Train loss: 0.3355179\n",
      "Epoch: 1794 Train loss: 0.3355058\n",
      "Epoch: 1795 Train loss: 0.3354939\n",
      "Epoch: 1796 Train loss: 0.3354819\n",
      "Epoch: 1797 Train loss: 0.3354698\n",
      "Epoch: 1798 Train loss: 0.3354579\n",
      "Epoch: 1799 Train loss: 0.3354460\n",
      "Epoch: 1800 Train loss: 0.3354342\n",
      "Epoch: 1801 Train loss: 0.3354222\n",
      "Epoch: 1802 Train loss: 0.3354106\n",
      "Epoch: 1803 Train loss: 0.3353987\n",
      "Epoch: 1804 Train loss: 0.3353871\n",
      "Epoch: 1805 Train loss: 0.3353754\n",
      "Epoch: 1806 Train loss: 0.3353637\n",
      "Epoch: 1807 Train loss: 0.3353522\n",
      "Epoch: 1808 Train loss: 0.3353406\n",
      "Epoch: 1809 Train loss: 0.3353290\n",
      "Epoch: 1810 Train loss: 0.3353175\n",
      "Epoch: 1811 Train loss: 0.3353060\n",
      "Epoch: 1812 Train loss: 0.3352945\n",
      "Epoch: 1813 Train loss: 0.3352831\n",
      "Epoch: 1814 Train loss: 0.3352717\n",
      "Epoch: 1815 Train loss: 0.3352604\n",
      "Epoch: 1816 Train loss: 0.3352491\n",
      "Epoch: 1817 Train loss: 0.3352377\n",
      "Epoch: 1818 Train loss: 0.3352265\n",
      "Epoch: 1819 Train loss: 0.3352153\n",
      "Epoch: 1820 Train loss: 0.3352041\n",
      "Epoch: 1821 Train loss: 0.3351929\n",
      "Epoch: 1822 Train loss: 0.3351817\n",
      "Epoch: 1823 Train loss: 0.3351705\n",
      "Epoch: 1824 Train loss: 0.3351596\n",
      "Epoch: 1825 Train loss: 0.3351484\n",
      "Epoch: 1826 Train loss: 0.3351375\n",
      "Epoch: 1827 Train loss: 0.3351264\n",
      "Epoch: 1828 Train loss: 0.3351155\n",
      "Epoch: 1829 Train loss: 0.3351045\n",
      "Epoch: 1830 Train loss: 0.3350936\n",
      "Epoch: 1831 Train loss: 0.3350828\n",
      "Epoch: 1832 Train loss: 0.3350721\n",
      "Epoch: 1833 Train loss: 0.3350613\n",
      "Epoch: 1834 Train loss: 0.3350505\n",
      "Epoch: 1835 Train loss: 0.3350397\n",
      "Epoch: 1836 Train loss: 0.3350290\n",
      "Epoch: 1837 Train loss: 0.3350181\n",
      "Epoch: 1838 Train loss: 0.3350075\n",
      "Epoch: 1839 Train loss: 0.3349968\n",
      "Epoch: 1840 Train loss: 0.3349862\n",
      "Epoch: 1841 Train loss: 0.3349756\n",
      "Epoch: 1842 Train loss: 0.3349650\n",
      "Epoch: 1843 Train loss: 0.3349545\n",
      "Epoch: 1844 Train loss: 0.3349439\n",
      "Epoch: 1845 Train loss: 0.3349335\n",
      "Epoch: 1846 Train loss: 0.3349229\n",
      "Epoch: 1847 Train loss: 0.3349125\n",
      "Epoch: 1848 Train loss: 0.3349021\n",
      "Epoch: 1849 Train loss: 0.3348918\n",
      "Epoch: 1850 Train loss: 0.3348814\n",
      "Epoch: 1851 Train loss: 0.3348711\n",
      "Epoch: 1852 Train loss: 0.3348607\n",
      "Epoch: 1853 Train loss: 0.3348505\n",
      "Epoch: 1854 Train loss: 0.3348402\n",
      "Epoch: 1855 Train loss: 0.3348301\n",
      "Epoch: 1856 Train loss: 0.3348198\n",
      "Epoch: 1857 Train loss: 0.3348097\n",
      "Epoch: 1858 Train loss: 0.3347995\n",
      "Epoch: 1859 Train loss: 0.3347894\n",
      "Epoch: 1860 Train loss: 0.3347792\n",
      "Epoch: 1861 Train loss: 0.3347691\n",
      "Epoch: 1862 Train loss: 0.3347590\n",
      "Epoch: 1863 Train loss: 0.3347490\n",
      "Epoch: 1864 Train loss: 0.3347390\n",
      "Epoch: 1865 Train loss: 0.3347289\n",
      "Epoch: 1866 Train loss: 0.3347188\n",
      "Epoch: 1867 Train loss: 0.3347088\n",
      "Epoch: 1868 Train loss: 0.3346988\n",
      "Epoch: 1869 Train loss: 0.3346889\n",
      "Epoch: 1870 Train loss: 0.3346790\n",
      "Epoch: 1871 Train loss: 0.3346691\n",
      "Epoch: 1872 Train loss: 0.3346593\n",
      "Epoch: 1873 Train loss: 0.3346494\n",
      "Epoch: 1874 Train loss: 0.3346397\n",
      "Epoch: 1875 Train loss: 0.3346299\n",
      "Epoch: 1876 Train loss: 0.3346202\n",
      "Epoch: 1877 Train loss: 0.3346104\n",
      "Epoch: 1878 Train loss: 0.3346008\n",
      "Epoch: 1879 Train loss: 0.3345910\n",
      "Epoch: 1880 Train loss: 0.3345813\n",
      "Epoch: 1881 Train loss: 0.3345717\n",
      "Epoch: 1882 Train loss: 0.3345621\n",
      "Epoch: 1883 Train loss: 0.3345524\n",
      "Epoch: 1884 Train loss: 0.3345429\n",
      "Epoch: 1885 Train loss: 0.3345334\n",
      "Epoch: 1886 Train loss: 0.3345238\n",
      "Epoch: 1887 Train loss: 0.3345143\n",
      "Epoch: 1888 Train loss: 0.3345048\n",
      "Epoch: 1889 Train loss: 0.3344954\n",
      "Epoch: 1890 Train loss: 0.3344859\n",
      "Epoch: 1891 Train loss: 0.3344764\n",
      "Epoch: 1892 Train loss: 0.3344671\n",
      "Epoch: 1893 Train loss: 0.3344577\n",
      "Epoch: 1894 Train loss: 0.3344483\n",
      "Epoch: 1895 Train loss: 0.3344390\n",
      "Epoch: 1896 Train loss: 0.3344295\n",
      "Epoch: 1897 Train loss: 0.3344202\n",
      "Epoch: 1898 Train loss: 0.3344108\n",
      "Epoch: 1899 Train loss: 0.3344017\n",
      "Epoch: 1900 Train loss: 0.3343924\n",
      "Epoch: 1901 Train loss: 0.3343831\n",
      "Epoch: 1902 Train loss: 0.3343739\n",
      "Epoch: 1903 Train loss: 0.3343648\n",
      "Epoch: 1904 Train loss: 0.3343556\n",
      "Epoch: 1905 Train loss: 0.3343464\n",
      "Epoch: 1906 Train loss: 0.3343373\n",
      "Epoch: 1907 Train loss: 0.3343282\n",
      "Epoch: 1908 Train loss: 0.3343191\n",
      "Epoch: 1909 Train loss: 0.3343101\n",
      "Epoch: 1910 Train loss: 0.3343010\n",
      "Epoch: 1911 Train loss: 0.3342920\n",
      "Epoch: 1912 Train loss: 0.3342827\n",
      "Epoch: 1913 Train loss: 0.3342737\n",
      "Epoch: 1914 Train loss: 0.3342647\n",
      "Epoch: 1915 Train loss: 0.3342558\n",
      "Epoch: 1916 Train loss: 0.3342468\n",
      "Epoch: 1917 Train loss: 0.3342378\n",
      "Epoch: 1918 Train loss: 0.3342290\n",
      "Epoch: 1919 Train loss: 0.3342200\n",
      "Epoch: 1920 Train loss: 0.3342112\n",
      "Epoch: 1921 Train loss: 0.3342024\n",
      "Epoch: 1922 Train loss: 0.3341935\n",
      "Epoch: 1923 Train loss: 0.3341847\n",
      "Epoch: 1924 Train loss: 0.3341759\n",
      "Epoch: 1925 Train loss: 0.3341671\n",
      "Epoch: 1926 Train loss: 0.3341583\n",
      "Epoch: 1927 Train loss: 0.3341495\n",
      "Epoch: 1928 Train loss: 0.3341407\n",
      "Epoch: 1929 Train loss: 0.3341320\n",
      "Epoch: 1930 Train loss: 0.3341233\n",
      "Epoch: 1931 Train loss: 0.3341146\n",
      "Epoch: 1932 Train loss: 0.3341059\n",
      "Epoch: 1933 Train loss: 0.3340973\n",
      "Epoch: 1934 Train loss: 0.3340887\n",
      "Epoch: 1935 Train loss: 0.3340802\n",
      "Epoch: 1936 Train loss: 0.3340716\n",
      "Epoch: 1937 Train loss: 0.3340629\n",
      "Epoch: 1938 Train loss: 0.3340543\n",
      "Epoch: 1939 Train loss: 0.3340458\n",
      "Epoch: 1940 Train loss: 0.3340372\n",
      "Epoch: 1941 Train loss: 0.3340288\n",
      "Epoch: 1942 Train loss: 0.3340203\n",
      "Epoch: 1943 Train loss: 0.3340118\n",
      "Epoch: 1944 Train loss: 0.3340034\n",
      "Epoch: 1945 Train loss: 0.3339950\n",
      "Epoch: 1946 Train loss: 0.3339865\n",
      "Epoch: 1947 Train loss: 0.3339781\n",
      "Epoch: 1948 Train loss: 0.3339697\n",
      "Epoch: 1949 Train loss: 0.3339614\n",
      "Epoch: 1950 Train loss: 0.3339530\n",
      "Epoch: 1951 Train loss: 0.3339447\n",
      "Epoch: 1952 Train loss: 0.3339364\n",
      "Epoch: 1953 Train loss: 0.3339281\n",
      "Epoch: 1954 Train loss: 0.3339197\n",
      "Epoch: 1955 Train loss: 0.3339115\n",
      "Epoch: 1956 Train loss: 0.3339033\n",
      "Epoch: 1957 Train loss: 0.3338950\n",
      "Epoch: 1958 Train loss: 0.3338867\n",
      "Epoch: 1959 Train loss: 0.3338785\n",
      "Epoch: 1960 Train loss: 0.3338703\n",
      "Epoch: 1961 Train loss: 0.3338620\n",
      "Epoch: 1962 Train loss: 0.3338538\n",
      "Epoch: 1963 Train loss: 0.3338456\n",
      "Epoch: 1964 Train loss: 0.3338374\n",
      "Epoch: 1965 Train loss: 0.3338292\n",
      "Epoch: 1966 Train loss: 0.3338211\n",
      "Epoch: 1967 Train loss: 0.3338130\n",
      "Epoch: 1968 Train loss: 0.3338050\n",
      "Epoch: 1969 Train loss: 0.3337970\n",
      "Epoch: 1970 Train loss: 0.3337889\n",
      "Epoch: 1971 Train loss: 0.3337809\n",
      "Epoch: 1972 Train loss: 0.3337729\n",
      "Epoch: 1973 Train loss: 0.3337648\n",
      "Epoch: 1974 Train loss: 0.3337568\n",
      "Epoch: 1975 Train loss: 0.3337489\n",
      "Epoch: 1976 Train loss: 0.3337409\n",
      "Epoch: 1977 Train loss: 0.3337331\n",
      "Epoch: 1978 Train loss: 0.3337251\n",
      "Epoch: 1979 Train loss: 0.3337171\n",
      "Epoch: 1980 Train loss: 0.3337093\n",
      "Epoch: 1981 Train loss: 0.3337015\n",
      "Epoch: 1982 Train loss: 0.3336936\n",
      "Epoch: 1983 Train loss: 0.3336857\n",
      "Epoch: 1984 Train loss: 0.3336779\n",
      "Epoch: 1985 Train loss: 0.3336700\n",
      "Epoch: 1986 Train loss: 0.3336622\n",
      "Epoch: 1987 Train loss: 0.3336544\n",
      "Epoch: 1988 Train loss: 0.3336467\n",
      "Epoch: 1989 Train loss: 0.3336389\n",
      "Epoch: 1990 Train loss: 0.3336311\n",
      "Epoch: 1991 Train loss: 0.3336233\n",
      "Epoch: 1992 Train loss: 0.3336156\n",
      "Epoch: 1993 Train loss: 0.3336080\n",
      "Epoch: 1994 Train loss: 0.3336003\n",
      "Epoch: 1995 Train loss: 0.3335925\n",
      "Epoch: 1996 Train loss: 0.3335848\n",
      "Epoch: 1997 Train loss: 0.3335771\n",
      "Epoch: 1998 Train loss: 0.3335696\n",
      "Epoch: 1999 Train loss: 0.3335619\n",
      "Epoch: 2000 Train loss: 0.3335543\n",
      "Epoch: 2001 Train loss: 0.3335467\n",
      "Epoch: 2002 Train loss: 0.3335391\n",
      "Epoch: 2003 Train loss: 0.3335316\n",
      "Epoch: 2004 Train loss: 0.3335240\n",
      "Epoch: 2005 Train loss: 0.3335165\n",
      "Epoch: 2006 Train loss: 0.3335089\n",
      "Epoch: 2007 Train loss: 0.3335015\n",
      "Epoch: 2008 Train loss: 0.3334940\n",
      "Epoch: 2009 Train loss: 0.3334864\n",
      "Epoch: 2010 Train loss: 0.3334790\n",
      "Epoch: 2011 Train loss: 0.3334715\n",
      "Epoch: 2012 Train loss: 0.3334641\n",
      "Epoch: 2013 Train loss: 0.3334567\n",
      "Epoch: 2014 Train loss: 0.3334492\n",
      "Epoch: 2015 Train loss: 0.3334417\n",
      "Epoch: 2016 Train loss: 0.3334343\n",
      "Epoch: 2017 Train loss: 0.3334269\n",
      "Epoch: 2018 Train loss: 0.3334195\n",
      "Epoch: 2019 Train loss: 0.3334121\n",
      "Epoch: 2020 Train loss: 0.3334048\n",
      "Epoch: 2021 Train loss: 0.3333975\n",
      "Epoch: 2022 Train loss: 0.3333901\n",
      "Epoch: 2023 Train loss: 0.3333829\n",
      "Epoch: 2024 Train loss: 0.3333757\n",
      "Epoch: 2025 Train loss: 0.3333683\n",
      "Epoch: 2026 Train loss: 0.3333610\n",
      "Epoch: 2027 Train loss: 0.3333538\n",
      "Epoch: 2028 Train loss: 0.3333465\n",
      "Epoch: 2029 Train loss: 0.3333393\n",
      "Epoch: 2030 Train loss: 0.3333322\n",
      "Epoch: 2031 Train loss: 0.3333250\n",
      "Epoch: 2032 Train loss: 0.3333177\n",
      "Epoch: 2033 Train loss: 0.3333105\n",
      "Epoch: 2034 Train loss: 0.3333032\n",
      "Epoch: 2035 Train loss: 0.3332961\n",
      "Epoch: 2036 Train loss: 0.3332889\n",
      "Epoch: 2037 Train loss: 0.3332818\n",
      "Epoch: 2038 Train loss: 0.3332747\n",
      "Epoch: 2039 Train loss: 0.3332676\n",
      "Epoch: 2040 Train loss: 0.3332604\n",
      "Epoch: 2041 Train loss: 0.3332534\n",
      "Epoch: 2042 Train loss: 0.3332463\n",
      "Epoch: 2043 Train loss: 0.3332393\n",
      "Epoch: 2044 Train loss: 0.3332323\n",
      "Epoch: 2045 Train loss: 0.3332252\n",
      "Epoch: 2046 Train loss: 0.3332182\n",
      "Epoch: 2047 Train loss: 0.3332113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2048 Train loss: 0.3332043\n",
      "Epoch: 2049 Train loss: 0.3331973\n",
      "Epoch: 2050 Train loss: 0.3331903\n",
      "Epoch: 2051 Train loss: 0.3331833\n",
      "Epoch: 2052 Train loss: 0.3331764\n",
      "Epoch: 2053 Train loss: 0.3331695\n",
      "Epoch: 2054 Train loss: 0.3331625\n",
      "Epoch: 2055 Train loss: 0.3331557\n",
      "Epoch: 2056 Train loss: 0.3331488\n",
      "Epoch: 2057 Train loss: 0.3331419\n",
      "Epoch: 2058 Train loss: 0.3331350\n",
      "Epoch: 2059 Train loss: 0.3331282\n",
      "Epoch: 2060 Train loss: 0.3331213\n",
      "Epoch: 2061 Train loss: 0.3331144\n",
      "Epoch: 2062 Train loss: 0.3331077\n",
      "Epoch: 2063 Train loss: 0.3331008\n",
      "Epoch: 2064 Train loss: 0.3330940\n",
      "Epoch: 2065 Train loss: 0.3330873\n",
      "Epoch: 2066 Train loss: 0.3330805\n",
      "Epoch: 2067 Train loss: 0.3330737\n",
      "Epoch: 2068 Train loss: 0.3330670\n",
      "Epoch: 2069 Train loss: 0.3330602\n",
      "Epoch: 2070 Train loss: 0.3330534\n",
      "Epoch: 2071 Train loss: 0.3330467\n",
      "Epoch: 2072 Train loss: 0.3330398\n",
      "Epoch: 2073 Train loss: 0.3330330\n",
      "Epoch: 2074 Train loss: 0.3330262\n",
      "Epoch: 2075 Train loss: 0.3330196\n",
      "Epoch: 2076 Train loss: 0.3330129\n",
      "Epoch: 2077 Train loss: 0.3330062\n",
      "Epoch: 2078 Train loss: 0.3329996\n",
      "Epoch: 2079 Train loss: 0.3329929\n",
      "Epoch: 2080 Train loss: 0.3329864\n",
      "Epoch: 2081 Train loss: 0.3329797\n",
      "Epoch: 2082 Train loss: 0.3329731\n",
      "Epoch: 2083 Train loss: 0.3329665\n",
      "Epoch: 2084 Train loss: 0.3329599\n",
      "Epoch: 2085 Train loss: 0.3329534\n",
      "Epoch: 2086 Train loss: 0.3329468\n",
      "Epoch: 2087 Train loss: 0.3329402\n",
      "Epoch: 2088 Train loss: 0.3329337\n",
      "Epoch: 2089 Train loss: 0.3329272\n",
      "Epoch: 2090 Train loss: 0.3329206\n",
      "Epoch: 2091 Train loss: 0.3329142\n",
      "Epoch: 2092 Train loss: 0.3329077\n",
      "Epoch: 2093 Train loss: 0.3329012\n",
      "Epoch: 2094 Train loss: 0.3328947\n",
      "Epoch: 2095 Train loss: 0.3328883\n",
      "Epoch: 2096 Train loss: 0.3328819\n",
      "Epoch: 2097 Train loss: 0.3328754\n",
      "Epoch: 2098 Train loss: 0.3328690\n",
      "Epoch: 2099 Train loss: 0.3328625\n",
      "Epoch: 2100 Train loss: 0.3328561\n",
      "Epoch: 2101 Train loss: 0.3328497\n",
      "Epoch: 2102 Train loss: 0.3328434\n",
      "Epoch: 2103 Train loss: 0.3328370\n",
      "Epoch: 2104 Train loss: 0.3328306\n",
      "Epoch: 2105 Train loss: 0.3328242\n",
      "Epoch: 2106 Train loss: 0.3328179\n",
      "Epoch: 2107 Train loss: 0.3328116\n",
      "Epoch: 2108 Train loss: 0.3328053\n",
      "Epoch: 2109 Train loss: 0.3327990\n",
      "Epoch: 2110 Train loss: 0.3327926\n",
      "Epoch: 2111 Train loss: 0.3327862\n",
      "Epoch: 2112 Train loss: 0.3327799\n",
      "Epoch: 2113 Train loss: 0.3327736\n",
      "Epoch: 2114 Train loss: 0.3327672\n",
      "Epoch: 2115 Train loss: 0.3327609\n",
      "Epoch: 2116 Train loss: 0.3327547\n",
      "Epoch: 2117 Train loss: 0.3327484\n",
      "Epoch: 2118 Train loss: 0.3327423\n",
      "Epoch: 2119 Train loss: 0.3327360\n",
      "Epoch: 2120 Train loss: 0.3327298\n",
      "Epoch: 2121 Train loss: 0.3327236\n",
      "Epoch: 2122 Train loss: 0.3327176\n",
      "Epoch: 2123 Train loss: 0.3327113\n",
      "Epoch: 2124 Train loss: 0.3327051\n",
      "Epoch: 2125 Train loss: 0.3326990\n",
      "Epoch: 2126 Train loss: 0.3326928\n",
      "Epoch: 2127 Train loss: 0.3326867\n",
      "Epoch: 2128 Train loss: 0.3326806\n",
      "Epoch: 2129 Train loss: 0.3326744\n",
      "Epoch: 2130 Train loss: 0.3326684\n",
      "Epoch: 2131 Train loss: 0.3326622\n",
      "Epoch: 2132 Train loss: 0.3326562\n",
      "Epoch: 2133 Train loss: 0.3326501\n",
      "Epoch: 2134 Train loss: 0.3326438\n",
      "Epoch: 2135 Train loss: 0.3326377\n",
      "Epoch: 2136 Train loss: 0.3326317\n",
      "Epoch: 2137 Train loss: 0.3326256\n",
      "Epoch: 2138 Train loss: 0.3326196\n",
      "Epoch: 2139 Train loss: 0.3326135\n",
      "Epoch: 2140 Train loss: 0.3326075\n",
      "Epoch: 2141 Train loss: 0.3326015\n",
      "Epoch: 2142 Train loss: 0.3325955\n",
      "Epoch: 2143 Train loss: 0.3325895\n",
      "Epoch: 2144 Train loss: 0.3325836\n",
      "Epoch: 2145 Train loss: 0.3325775\n",
      "Epoch: 2146 Train loss: 0.3325717\n",
      "Epoch: 2147 Train loss: 0.3325657\n",
      "Epoch: 2148 Train loss: 0.3325598\n",
      "Epoch: 2149 Train loss: 0.3325538\n",
      "Epoch: 2150 Train loss: 0.3325480\n",
      "Epoch: 2151 Train loss: 0.3325421\n",
      "Epoch: 2152 Train loss: 0.3325361\n",
      "Epoch: 2153 Train loss: 0.3325301\n",
      "Epoch: 2154 Train loss: 0.3325242\n",
      "Epoch: 2155 Train loss: 0.3325183\n",
      "Epoch: 2156 Train loss: 0.3325124\n",
      "Epoch: 2157 Train loss: 0.3325065\n",
      "Epoch: 2158 Train loss: 0.3325006\n",
      "Epoch: 2159 Train loss: 0.3324947\n",
      "Epoch: 2160 Train loss: 0.3324889\n",
      "Epoch: 2161 Train loss: 0.3324831\n",
      "Epoch: 2162 Train loss: 0.3324772\n",
      "Epoch: 2163 Train loss: 0.3324715\n",
      "Epoch: 2164 Train loss: 0.3324657\n",
      "Epoch: 2165 Train loss: 0.3324599\n",
      "Epoch: 2166 Train loss: 0.3324541\n",
      "Epoch: 2167 Train loss: 0.3324485\n",
      "Epoch: 2168 Train loss: 0.3324426\n",
      "Epoch: 2169 Train loss: 0.3324369\n",
      "Epoch: 2170 Train loss: 0.3324312\n",
      "Epoch: 2171 Train loss: 0.3324254\n",
      "Epoch: 2172 Train loss: 0.3324197\n",
      "Epoch: 2173 Train loss: 0.3324140\n",
      "Epoch: 2174 Train loss: 0.3324083\n",
      "Epoch: 2175 Train loss: 0.3324026\n",
      "Epoch: 2176 Train loss: 0.3323968\n",
      "Epoch: 2177 Train loss: 0.3323912\n",
      "Epoch: 2178 Train loss: 0.3323855\n",
      "Epoch: 2179 Train loss: 0.3323799\n",
      "Epoch: 2180 Train loss: 0.3323742\n",
      "Epoch: 2181 Train loss: 0.3323686\n",
      "Epoch: 2182 Train loss: 0.3323628\n",
      "Epoch: 2183 Train loss: 0.3323572\n",
      "Epoch: 2184 Train loss: 0.3323516\n",
      "Epoch: 2185 Train loss: 0.3323460\n",
      "Epoch: 2186 Train loss: 0.3323404\n",
      "Epoch: 2187 Train loss: 0.3323348\n",
      "Epoch: 2188 Train loss: 0.3323292\n",
      "Epoch: 2189 Train loss: 0.3323235\n",
      "Epoch: 2190 Train loss: 0.3323180\n",
      "Epoch: 2191 Train loss: 0.3323125\n",
      "Epoch: 2192 Train loss: 0.3323069\n",
      "Epoch: 2193 Train loss: 0.3323014\n",
      "Epoch: 2194 Train loss: 0.3322958\n",
      "Epoch: 2195 Train loss: 0.3322903\n",
      "Epoch: 2196 Train loss: 0.3322847\n",
      "Epoch: 2197 Train loss: 0.3322791\n",
      "Epoch: 2198 Train loss: 0.3322735\n",
      "Epoch: 2199 Train loss: 0.3322680\n",
      "Epoch: 2200 Train loss: 0.3322624\n",
      "Epoch: 2201 Train loss: 0.3322568\n",
      "Epoch: 2202 Train loss: 0.3322513\n",
      "Epoch: 2203 Train loss: 0.3322459\n",
      "Epoch: 2204 Train loss: 0.3322404\n",
      "Epoch: 2205 Train loss: 0.3322349\n",
      "Epoch: 2206 Train loss: 0.3322294\n",
      "Epoch: 2207 Train loss: 0.3322240\n",
      "Epoch: 2208 Train loss: 0.3322184\n",
      "Epoch: 2209 Train loss: 0.3322131\n",
      "Epoch: 2210 Train loss: 0.3322077\n",
      "Epoch: 2211 Train loss: 0.3322023\n",
      "Epoch: 2212 Train loss: 0.3321969\n",
      "Epoch: 2213 Train loss: 0.3321914\n",
      "Epoch: 2214 Train loss: 0.3321860\n",
      "Epoch: 2215 Train loss: 0.3321807\n",
      "Epoch: 2216 Train loss: 0.3321753\n",
      "Epoch: 2217 Train loss: 0.3321700\n",
      "Epoch: 2218 Train loss: 0.3321646\n",
      "Epoch: 2219 Train loss: 0.3321593\n",
      "Epoch: 2220 Train loss: 0.3321539\n",
      "Epoch: 2221 Train loss: 0.3321486\n",
      "Epoch: 2222 Train loss: 0.3321433\n",
      "Epoch: 2223 Train loss: 0.3321380\n",
      "Epoch: 2224 Train loss: 0.3321326\n",
      "Epoch: 2225 Train loss: 0.3321274\n",
      "Epoch: 2226 Train loss: 0.3321221\n",
      "Epoch: 2227 Train loss: 0.3321169\n",
      "Epoch: 2228 Train loss: 0.3321115\n",
      "Epoch: 2229 Train loss: 0.3321063\n",
      "Epoch: 2230 Train loss: 0.3321010\n",
      "Epoch: 2231 Train loss: 0.3320958\n",
      "Epoch: 2232 Train loss: 0.3320906\n",
      "Epoch: 2233 Train loss: 0.3320853\n",
      "Epoch: 2234 Train loss: 0.3320802\n",
      "Epoch: 2235 Train loss: 0.3320749\n",
      "Epoch: 2236 Train loss: 0.3320697\n",
      "Epoch: 2237 Train loss: 0.3320644\n",
      "Epoch: 2238 Train loss: 0.3320592\n",
      "Epoch: 2239 Train loss: 0.3320540\n",
      "Epoch: 2240 Train loss: 0.3320487\n",
      "Epoch: 2241 Train loss: 0.3320436\n",
      "Epoch: 2242 Train loss: 0.3320384\n",
      "Epoch: 2243 Train loss: 0.3320332\n",
      "Epoch: 2244 Train loss: 0.3320281\n",
      "Epoch: 2245 Train loss: 0.3320228\n",
      "Epoch: 2246 Train loss: 0.3320176\n",
      "Epoch: 2247 Train loss: 0.3320124\n",
      "Epoch: 2248 Train loss: 0.3320072\n",
      "Epoch: 2249 Train loss: 0.3320021\n",
      "Epoch: 2250 Train loss: 0.3319971\n",
      "Epoch: 2251 Train loss: 0.3319919\n",
      "Epoch: 2252 Train loss: 0.3319869\n",
      "Epoch: 2253 Train loss: 0.3319818\n",
      "Epoch: 2254 Train loss: 0.3319767\n",
      "Epoch: 2255 Train loss: 0.3319715\n",
      "Epoch: 2256 Train loss: 0.3319664\n",
      "Epoch: 2257 Train loss: 0.3319614\n",
      "Epoch: 2258 Train loss: 0.3319562\n",
      "Epoch: 2259 Train loss: 0.3319511\n",
      "Epoch: 2260 Train loss: 0.3319460\n",
      "Epoch: 2261 Train loss: 0.3319410\n",
      "Epoch: 2262 Train loss: 0.3319359\n",
      "Epoch: 2263 Train loss: 0.3319309\n",
      "Epoch: 2264 Train loss: 0.3319258\n",
      "Epoch: 2265 Train loss: 0.3319208\n",
      "Epoch: 2266 Train loss: 0.3319159\n",
      "Epoch: 2267 Train loss: 0.3319108\n",
      "Epoch: 2268 Train loss: 0.3319058\n",
      "Epoch: 2269 Train loss: 0.3319008\n",
      "Epoch: 2270 Train loss: 0.3318958\n",
      "Epoch: 2271 Train loss: 0.3318909\n",
      "Epoch: 2272 Train loss: 0.3318858\n",
      "Epoch: 2273 Train loss: 0.3318807\n",
      "Epoch: 2274 Train loss: 0.3318758\n",
      "Epoch: 2275 Train loss: 0.3318707\n",
      "Epoch: 2276 Train loss: 0.3318656\n",
      "Epoch: 2277 Train loss: 0.3318606\n",
      "Epoch: 2278 Train loss: 0.3318558\n",
      "Epoch: 2279 Train loss: 0.3318507\n",
      "Epoch: 2280 Train loss: 0.3318458\n",
      "Epoch: 2281 Train loss: 0.3318408\n",
      "Epoch: 2282 Train loss: 0.3318360\n",
      "Epoch: 2283 Train loss: 0.3318310\n",
      "Epoch: 2284 Train loss: 0.3318261\n",
      "Epoch: 2285 Train loss: 0.3318211\n",
      "Epoch: 2286 Train loss: 0.3318163\n",
      "Epoch: 2287 Train loss: 0.3318113\n",
      "Epoch: 2288 Train loss: 0.3318063\n",
      "Epoch: 2289 Train loss: 0.3318014\n",
      "Epoch: 2290 Train loss: 0.3317965\n",
      "Epoch: 2291 Train loss: 0.3317916\n",
      "Epoch: 2292 Train loss: 0.3317868\n",
      "Epoch: 2293 Train loss: 0.3317818\n",
      "Epoch: 2294 Train loss: 0.3317768\n",
      "Epoch: 2295 Train loss: 0.3317718\n",
      "Epoch: 2296 Train loss: 0.3317668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2297 Train loss: 0.3317619\n",
      "Epoch: 2298 Train loss: 0.3317569\n",
      "Epoch: 2299 Train loss: 0.3317519\n",
      "Epoch: 2300 Train loss: 0.3317469\n",
      "Epoch: 2301 Train loss: 0.3317418\n",
      "Epoch: 2302 Train loss: 0.3317369\n",
      "Epoch: 2303 Train loss: 0.3317319\n",
      "Epoch: 2304 Train loss: 0.3317268\n",
      "Epoch: 2305 Train loss: 0.3317217\n",
      "Epoch: 2306 Train loss: 0.3317166\n",
      "Epoch: 2307 Train loss: 0.3317114\n",
      "Epoch: 2308 Train loss: 0.3317061\n",
      "Epoch: 2309 Train loss: 0.3317007\n",
      "Epoch: 2310 Train loss: 0.3316952\n",
      "Epoch: 2311 Train loss: 0.3316895\n",
      "Epoch: 2312 Train loss: 0.3316836\n",
      "Epoch: 2313 Train loss: 0.3316774\n",
      "Epoch: 2314 Train loss: 0.3316709\n",
      "Epoch: 2315 Train loss: 0.3316634\n",
      "Epoch: 2316 Train loss: 0.3316550\n",
      "Epoch: 2317 Train loss: 0.3316447\n",
      "Epoch: 2318 Train loss: 0.3316311\n",
      "Epoch: 2319 Train loss: 0.3316121\n",
      "Epoch: 2320 Train loss: 0.3315844\n",
      "Epoch: 2321 Train loss: 0.3315509\n",
      "Epoch: 2322 Train loss: 0.3315241\n",
      "Epoch: 2323 Train loss: 0.3315060\n",
      "Epoch: 2324 Train loss: 0.3314829\n",
      "Epoch: 2325 Train loss: 0.3314547\n",
      "Epoch: 2326 Train loss: 0.3314311\n",
      "Epoch: 2327 Train loss: 0.3314170\n",
      "Epoch: 2328 Train loss: 0.3314073\n",
      "Epoch: 2329 Train loss: 0.3313933\n",
      "Epoch: 2330 Train loss: 0.3313723\n",
      "Epoch: 2331 Train loss: 0.3313471\n",
      "Epoch: 2332 Train loss: 0.3313243\n",
      "Epoch: 2333 Train loss: 0.3313082\n",
      "Epoch: 2334 Train loss: 0.3312940\n",
      "Epoch: 2335 Train loss: 0.3312723\n",
      "Epoch: 2336 Train loss: 0.3312478\n",
      "Epoch: 2337 Train loss: 0.3312317\n",
      "Epoch: 2338 Train loss: 0.3312228\n",
      "Epoch: 2339 Train loss: 0.3312126\n",
      "Epoch: 2340 Train loss: 0.3311985\n",
      "Epoch: 2341 Train loss: 0.3311850\n",
      "Epoch: 2342 Train loss: 0.3311750\n",
      "Epoch: 2343 Train loss: 0.3311662\n",
      "Epoch: 2344 Train loss: 0.3311567\n",
      "Epoch: 2345 Train loss: 0.3311465\n",
      "Epoch: 2346 Train loss: 0.3311366\n",
      "Epoch: 2347 Train loss: 0.3311274\n",
      "Epoch: 2348 Train loss: 0.3311192\n",
      "Epoch: 2349 Train loss: 0.3311116\n",
      "Epoch: 2350 Train loss: 0.3311043\n",
      "Epoch: 2351 Train loss: 0.3310969\n",
      "Epoch: 2352 Train loss: 0.3310893\n",
      "Epoch: 2353 Train loss: 0.3310819\n",
      "Epoch: 2354 Train loss: 0.3310748\n",
      "Epoch: 2355 Train loss: 0.3310680\n",
      "Epoch: 2356 Train loss: 0.3310613\n",
      "Epoch: 2357 Train loss: 0.3310544\n",
      "Epoch: 2358 Train loss: 0.3310476\n",
      "Epoch: 2359 Train loss: 0.3310409\n",
      "Epoch: 2360 Train loss: 0.3310343\n",
      "Epoch: 2361 Train loss: 0.3310277\n",
      "Epoch: 2362 Train loss: 0.3310210\n",
      "Epoch: 2363 Train loss: 0.3310145\n",
      "Epoch: 2364 Train loss: 0.3310079\n",
      "Epoch: 2365 Train loss: 0.3310015\n",
      "Epoch: 2366 Train loss: 0.3309951\n",
      "Epoch: 2367 Train loss: 0.3309885\n",
      "Epoch: 2368 Train loss: 0.3309819\n",
      "Epoch: 2369 Train loss: 0.3309751\n",
      "Epoch: 2370 Train loss: 0.3309680\n",
      "Epoch: 2371 Train loss: 0.3309607\n",
      "Epoch: 2372 Train loss: 0.3309526\n",
      "Epoch: 2373 Train loss: 0.3309438\n",
      "Epoch: 2374 Train loss: 0.3309334\n",
      "Epoch: 2375 Train loss: 0.3309203\n",
      "Epoch: 2376 Train loss: 0.3309020\n",
      "Epoch: 2377 Train loss: 0.3308747\n",
      "Epoch: 2378 Train loss: 0.3308387\n",
      "Epoch: 2379 Train loss: 0.3308083\n",
      "Epoch: 2380 Train loss: 0.3307907\n",
      "Epoch: 2381 Train loss: 0.3307713\n",
      "Epoch: 2382 Train loss: 0.3307500\n",
      "Epoch: 2383 Train loss: 0.3307348\n",
      "Epoch: 2384 Train loss: 0.3307238\n",
      "Epoch: 2385 Train loss: 0.3307083\n",
      "Epoch: 2386 Train loss: 0.3306904\n",
      "Epoch: 2387 Train loss: 0.3306785\n",
      "Epoch: 2388 Train loss: 0.3306728\n",
      "Epoch: 2389 Train loss: 0.3306685\n",
      "Epoch: 2390 Train loss: 0.3306629\n",
      "Epoch: 2391 Train loss: 0.3306572\n",
      "Epoch: 2392 Train loss: 0.3306524\n",
      "Epoch: 2393 Train loss: 0.3306466\n",
      "Epoch: 2394 Train loss: 0.3306385\n",
      "Epoch: 2395 Train loss: 0.3306299\n",
      "Epoch: 2396 Train loss: 0.3306231\n",
      "Epoch: 2397 Train loss: 0.3306178\n",
      "Epoch: 2398 Train loss: 0.3306126\n",
      "Epoch: 2399 Train loss: 0.3306065\n",
      "Epoch: 2400 Train loss: 0.3306001\n",
      "Epoch: 2401 Train loss: 0.3305944\n",
      "Epoch: 2402 Train loss: 0.3305888\n",
      "Epoch: 2403 Train loss: 0.3305825\n",
      "Epoch: 2404 Train loss: 0.3305756\n",
      "Epoch: 2405 Train loss: 0.3305688\n",
      "Epoch: 2406 Train loss: 0.3305629\n",
      "Epoch: 2407 Train loss: 0.3305576\n",
      "Epoch: 2408 Train loss: 0.3305524\n",
      "Epoch: 2409 Train loss: 0.3305469\n",
      "Epoch: 2410 Train loss: 0.3305416\n",
      "Epoch: 2411 Train loss: 0.3305362\n",
      "Epoch: 2412 Train loss: 0.3305309\n",
      "Epoch: 2413 Train loss: 0.3305255\n",
      "Epoch: 2414 Train loss: 0.3305202\n",
      "Epoch: 2415 Train loss: 0.3305150\n",
      "Epoch: 2416 Train loss: 0.3305099\n",
      "Epoch: 2417 Train loss: 0.3305050\n",
      "Epoch: 2418 Train loss: 0.3305001\n",
      "Epoch: 2419 Train loss: 0.3304950\n",
      "Epoch: 2420 Train loss: 0.3304900\n",
      "Epoch: 2421 Train loss: 0.3304850\n",
      "Epoch: 2422 Train loss: 0.3304800\n",
      "Epoch: 2423 Train loss: 0.3304749\n",
      "Epoch: 2424 Train loss: 0.3304698\n",
      "Epoch: 2425 Train loss: 0.3304649\n",
      "Epoch: 2426 Train loss: 0.3304600\n",
      "Epoch: 2427 Train loss: 0.3304551\n",
      "Epoch: 2428 Train loss: 0.3304503\n",
      "Epoch: 2429 Train loss: 0.3304453\n",
      "Epoch: 2430 Train loss: 0.3304403\n",
      "Epoch: 2431 Train loss: 0.3304353\n",
      "Epoch: 2432 Train loss: 0.3304306\n",
      "Epoch: 2433 Train loss: 0.3304257\n",
      "Epoch: 2434 Train loss: 0.3304209\n",
      "Epoch: 2435 Train loss: 0.3304161\n",
      "Epoch: 2436 Train loss: 0.3304114\n",
      "Epoch: 2437 Train loss: 0.3304066\n",
      "Epoch: 2438 Train loss: 0.3304018\n",
      "Epoch: 2439 Train loss: 0.3303971\n",
      "Epoch: 2440 Train loss: 0.3303923\n",
      "Epoch: 2441 Train loss: 0.3303874\n",
      "Epoch: 2442 Train loss: 0.3303828\n",
      "Epoch: 2443 Train loss: 0.3303781\n",
      "Epoch: 2444 Train loss: 0.3303733\n",
      "Epoch: 2445 Train loss: 0.3303688\n",
      "Epoch: 2446 Train loss: 0.3303640\n",
      "Epoch: 2447 Train loss: 0.3303593\n",
      "Epoch: 2448 Train loss: 0.3303547\n",
      "Epoch: 2449 Train loss: 0.3303501\n",
      "Epoch: 2450 Train loss: 0.3303455\n",
      "Epoch: 2451 Train loss: 0.3303410\n",
      "Epoch: 2452 Train loss: 0.3303363\n",
      "Epoch: 2453 Train loss: 0.3303318\n",
      "Epoch: 2454 Train loss: 0.3303272\n",
      "Epoch: 2455 Train loss: 0.3303227\n",
      "Epoch: 2456 Train loss: 0.3303182\n",
      "Epoch: 2457 Train loss: 0.3303137\n",
      "Epoch: 2458 Train loss: 0.3303090\n",
      "Epoch: 2459 Train loss: 0.3303046\n",
      "Epoch: 2460 Train loss: 0.3303002\n",
      "Epoch: 2461 Train loss: 0.3302956\n",
      "Epoch: 2462 Train loss: 0.3302910\n",
      "Epoch: 2463 Train loss: 0.3302865\n",
      "Epoch: 2464 Train loss: 0.3302820\n",
      "Epoch: 2465 Train loss: 0.3302775\n",
      "Epoch: 2466 Train loss: 0.3302731\n",
      "Epoch: 2467 Train loss: 0.3302686\n",
      "Epoch: 2468 Train loss: 0.3302642\n",
      "Epoch: 2469 Train loss: 0.3302597\n",
      "Epoch: 2470 Train loss: 0.3302554\n",
      "Epoch: 2471 Train loss: 0.3302509\n",
      "Epoch: 2472 Train loss: 0.3302465\n",
      "Epoch: 2473 Train loss: 0.3302422\n",
      "Epoch: 2474 Train loss: 0.3302378\n",
      "Epoch: 2475 Train loss: 0.3302334\n",
      "Epoch: 2476 Train loss: 0.3302292\n",
      "Epoch: 2477 Train loss: 0.3302248\n",
      "Epoch: 2478 Train loss: 0.3302204\n",
      "Epoch: 2479 Train loss: 0.3302161\n",
      "Epoch: 2480 Train loss: 0.3302118\n",
      "Epoch: 2481 Train loss: 0.3302075\n",
      "Epoch: 2482 Train loss: 0.3302032\n",
      "Epoch: 2483 Train loss: 0.3301989\n",
      "Epoch: 2484 Train loss: 0.3301944\n",
      "Epoch: 2485 Train loss: 0.3301903\n",
      "Epoch: 2486 Train loss: 0.3301859\n",
      "Epoch: 2487 Train loss: 0.3301816\n",
      "Epoch: 2488 Train loss: 0.3301773\n",
      "Epoch: 2489 Train loss: 0.3301731\n",
      "Epoch: 2490 Train loss: 0.3301688\n",
      "Epoch: 2491 Train loss: 0.3301646\n",
      "Epoch: 2492 Train loss: 0.3301603\n",
      "Epoch: 2493 Train loss: 0.3301562\n",
      "Epoch: 2494 Train loss: 0.3301519\n",
      "Epoch: 2495 Train loss: 0.3301477\n",
      "Epoch: 2496 Train loss: 0.3301435\n",
      "Epoch: 2497 Train loss: 0.3301393\n",
      "Epoch: 2498 Train loss: 0.3301352\n",
      "Epoch: 2499 Train loss: 0.3301310\n",
      "Epoch: 2500 Train loss: 0.3301268\n",
      "Epoch: 2501 Train loss: 0.3301227\n",
      "Epoch: 2502 Train loss: 0.3301185\n",
      "Epoch: 2503 Train loss: 0.3301143\n",
      "Epoch: 2504 Train loss: 0.3301102\n",
      "Epoch: 2505 Train loss: 0.3301060\n",
      "Epoch: 2506 Train loss: 0.3301020\n",
      "Epoch: 2507 Train loss: 0.3300978\n",
      "Epoch: 2508 Train loss: 0.3300937\n",
      "Epoch: 2509 Train loss: 0.3300896\n",
      "Epoch: 2510 Train loss: 0.3300855\n",
      "Epoch: 2511 Train loss: 0.3300814\n",
      "Epoch: 2512 Train loss: 0.3300773\n",
      "Epoch: 2513 Train loss: 0.3300732\n",
      "Epoch: 2514 Train loss: 0.3300692\n",
      "Epoch: 2515 Train loss: 0.3300650\n",
      "Epoch: 2516 Train loss: 0.3300610\n",
      "Epoch: 2517 Train loss: 0.3300569\n",
      "Epoch: 2518 Train loss: 0.3300529\n",
      "Epoch: 2519 Train loss: 0.3300489\n",
      "Epoch: 2520 Train loss: 0.3300447\n",
      "Epoch: 2521 Train loss: 0.3300408\n",
      "Epoch: 2522 Train loss: 0.3300368\n",
      "Epoch: 2523 Train loss: 0.3300328\n",
      "Epoch: 2524 Train loss: 0.3300287\n",
      "Epoch: 2525 Train loss: 0.3300246\n",
      "Epoch: 2526 Train loss: 0.3300206\n",
      "Epoch: 2527 Train loss: 0.3300166\n",
      "Epoch: 2528 Train loss: 0.3300126\n",
      "Epoch: 2529 Train loss: 0.3300086\n",
      "Epoch: 2530 Train loss: 0.3300047\n",
      "Epoch: 2531 Train loss: 0.3300006\n",
      "Epoch: 2532 Train loss: 0.3299966\n",
      "Epoch: 2533 Train loss: 0.3299926\n",
      "Epoch: 2534 Train loss: 0.3299887\n",
      "Epoch: 2535 Train loss: 0.3299847\n",
      "Epoch: 2536 Train loss: 0.3299807\n",
      "Epoch: 2537 Train loss: 0.3299768\n",
      "Epoch: 2538 Train loss: 0.3299728\n",
      "Epoch: 2539 Train loss: 0.3299689\n",
      "Epoch: 2540 Train loss: 0.3299650\n",
      "Epoch: 2541 Train loss: 0.3299611\n",
      "Epoch: 2542 Train loss: 0.3299573\n",
      "Epoch: 2543 Train loss: 0.3299533\n",
      "Epoch: 2544 Train loss: 0.3299495\n",
      "Epoch: 2545 Train loss: 0.3299457\n",
      "Epoch: 2546 Train loss: 0.3299417\n",
      "Epoch: 2547 Train loss: 0.3299378\n",
      "Epoch: 2548 Train loss: 0.3299340\n",
      "Epoch: 2549 Train loss: 0.3299302\n",
      "Epoch: 2550 Train loss: 0.3299263\n",
      "Epoch: 2551 Train loss: 0.3299225\n",
      "Epoch: 2552 Train loss: 0.3299187\n",
      "Epoch: 2553 Train loss: 0.3299148\n",
      "Epoch: 2554 Train loss: 0.3299111\n",
      "Epoch: 2555 Train loss: 0.3299072\n",
      "Epoch: 2556 Train loss: 0.3299034\n",
      "Epoch: 2557 Train loss: 0.3298995\n",
      "Epoch: 2558 Train loss: 0.3298958\n",
      "Epoch: 2559 Train loss: 0.3298921\n",
      "Epoch: 2560 Train loss: 0.3298882\n",
      "Epoch: 2561 Train loss: 0.3298845\n",
      "Epoch: 2562 Train loss: 0.3298807\n",
      "Epoch: 2563 Train loss: 0.3298769\n",
      "Epoch: 2564 Train loss: 0.3298731\n",
      "Epoch: 2565 Train loss: 0.3298694\n",
      "Epoch: 2566 Train loss: 0.3298656\n",
      "Epoch: 2567 Train loss: 0.3298619\n",
      "Epoch: 2568 Train loss: 0.3298582\n",
      "Epoch: 2569 Train loss: 0.3298544\n",
      "Epoch: 2570 Train loss: 0.3298508\n",
      "Epoch: 2571 Train loss: 0.3298470\n",
      "Epoch: 2572 Train loss: 0.3298433\n",
      "Epoch: 2573 Train loss: 0.3298396\n",
      "Epoch: 2574 Train loss: 0.3298358\n",
      "Epoch: 2575 Train loss: 0.3298321\n",
      "Epoch: 2576 Train loss: 0.3298284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2577 Train loss: 0.3298247\n",
      "Epoch: 2578 Train loss: 0.3298211\n",
      "Epoch: 2579 Train loss: 0.3298173\n",
      "Epoch: 2580 Train loss: 0.3298137\n",
      "Epoch: 2581 Train loss: 0.3298100\n",
      "Epoch: 2582 Train loss: 0.3298064\n",
      "Epoch: 2583 Train loss: 0.3298028\n",
      "Epoch: 2584 Train loss: 0.3297992\n",
      "Epoch: 2585 Train loss: 0.3297954\n",
      "Epoch: 2586 Train loss: 0.3297919\n",
      "Epoch: 2587 Train loss: 0.3297881\n",
      "Epoch: 2588 Train loss: 0.3297844\n",
      "Epoch: 2589 Train loss: 0.3297809\n",
      "Epoch: 2590 Train loss: 0.3297772\n",
      "Epoch: 2591 Train loss: 0.3297737\n",
      "Epoch: 2592 Train loss: 0.3297700\n",
      "Epoch: 2593 Train loss: 0.3297663\n",
      "Epoch: 2594 Train loss: 0.3297626\n",
      "Epoch: 2595 Train loss: 0.3297589\n",
      "Epoch: 2596 Train loss: 0.3297554\n",
      "Epoch: 2597 Train loss: 0.3297519\n",
      "Epoch: 2598 Train loss: 0.3297482\n",
      "Epoch: 2599 Train loss: 0.3297447\n",
      "Epoch: 2600 Train loss: 0.3297411\n",
      "Epoch: 2601 Train loss: 0.3297374\n",
      "Epoch: 2602 Train loss: 0.3297340\n",
      "Epoch: 2603 Train loss: 0.3297304\n",
      "Epoch: 2604 Train loss: 0.3297269\n",
      "Epoch: 2605 Train loss: 0.3297234\n",
      "Epoch: 2606 Train loss: 0.3297198\n",
      "Epoch: 2607 Train loss: 0.3297164\n",
      "Epoch: 2608 Train loss: 0.3297127\n",
      "Epoch: 2609 Train loss: 0.3297093\n",
      "Epoch: 2610 Train loss: 0.3297056\n",
      "Epoch: 2611 Train loss: 0.3297021\n",
      "Epoch: 2612 Train loss: 0.3296987\n",
      "Epoch: 2613 Train loss: 0.3296951\n",
      "Epoch: 2614 Train loss: 0.3296915\n",
      "Epoch: 2615 Train loss: 0.3296882\n",
      "Epoch: 2616 Train loss: 0.3296846\n",
      "Epoch: 2617 Train loss: 0.3296812\n",
      "Epoch: 2618 Train loss: 0.3296776\n",
      "Epoch: 2619 Train loss: 0.3296742\n",
      "Epoch: 2620 Train loss: 0.3296707\n",
      "Epoch: 2621 Train loss: 0.3296672\n",
      "Epoch: 2622 Train loss: 0.3296638\n",
      "Epoch: 2623 Train loss: 0.3296603\n",
      "Epoch: 2624 Train loss: 0.3296569\n",
      "Epoch: 2625 Train loss: 0.3296534\n",
      "Epoch: 2626 Train loss: 0.3296499\n",
      "Epoch: 2627 Train loss: 0.3296466\n",
      "Epoch: 2628 Train loss: 0.3296430\n",
      "Epoch: 2629 Train loss: 0.3296397\n",
      "Epoch: 2630 Train loss: 0.3296362\n",
      "Epoch: 2631 Train loss: 0.3296328\n",
      "Epoch: 2632 Train loss: 0.3296295\n",
      "Epoch: 2633 Train loss: 0.3296261\n",
      "Epoch: 2634 Train loss: 0.3296226\n",
      "Epoch: 2635 Train loss: 0.3296192\n",
      "Epoch: 2636 Train loss: 0.3296156\n",
      "Epoch: 2637 Train loss: 0.3296123\n",
      "Epoch: 2638 Train loss: 0.3296088\n",
      "Epoch: 2639 Train loss: 0.3296055\n",
      "Epoch: 2640 Train loss: 0.3296022\n",
      "Epoch: 2641 Train loss: 0.3295987\n",
      "Epoch: 2642 Train loss: 0.3295954\n",
      "Epoch: 2643 Train loss: 0.3295920\n",
      "Epoch: 2644 Train loss: 0.3295887\n",
      "Epoch: 2645 Train loss: 0.3295853\n",
      "Epoch: 2646 Train loss: 0.3295819\n",
      "Epoch: 2647 Train loss: 0.3295786\n",
      "Epoch: 2648 Train loss: 0.3295752\n",
      "Epoch: 2649 Train loss: 0.3295720\n",
      "Epoch: 2650 Train loss: 0.3295685\n",
      "Epoch: 2651 Train loss: 0.3295652\n",
      "Epoch: 2652 Train loss: 0.3295619\n",
      "Epoch: 2653 Train loss: 0.3295586\n",
      "Epoch: 2654 Train loss: 0.3295553\n",
      "Epoch: 2655 Train loss: 0.3295521\n",
      "Epoch: 2656 Train loss: 0.3295487\n",
      "Epoch: 2657 Train loss: 0.3295454\n",
      "Epoch: 2658 Train loss: 0.3295420\n",
      "Epoch: 2659 Train loss: 0.3295387\n",
      "Epoch: 2660 Train loss: 0.3295354\n",
      "Epoch: 2661 Train loss: 0.3295322\n",
      "Epoch: 2662 Train loss: 0.3295288\n",
      "Epoch: 2663 Train loss: 0.3295256\n",
      "Epoch: 2664 Train loss: 0.3295223\n",
      "Epoch: 2665 Train loss: 0.3295189\n",
      "Epoch: 2666 Train loss: 0.3295156\n",
      "Epoch: 2667 Train loss: 0.3295122\n",
      "Epoch: 2668 Train loss: 0.3295092\n",
      "Epoch: 2669 Train loss: 0.3295058\n",
      "Epoch: 2670 Train loss: 0.3295026\n",
      "Epoch: 2671 Train loss: 0.3294993\n",
      "Epoch: 2672 Train loss: 0.3294961\n",
      "Epoch: 2673 Train loss: 0.3294928\n",
      "Epoch: 2674 Train loss: 0.3294897\n",
      "Epoch: 2675 Train loss: 0.3294864\n",
      "Epoch: 2676 Train loss: 0.3294832\n",
      "Epoch: 2677 Train loss: 0.3294799\n",
      "Epoch: 2678 Train loss: 0.3294767\n",
      "Epoch: 2679 Train loss: 0.3294734\n",
      "Epoch: 2680 Train loss: 0.3294704\n",
      "Epoch: 2681 Train loss: 0.3294670\n",
      "Epoch: 2682 Train loss: 0.3294639\n",
      "Epoch: 2683 Train loss: 0.3294606\n",
      "Epoch: 2684 Train loss: 0.3294574\n",
      "Epoch: 2685 Train loss: 0.3294543\n",
      "Epoch: 2686 Train loss: 0.3294511\n",
      "Epoch: 2687 Train loss: 0.3294480\n",
      "Epoch: 2688 Train loss: 0.3294448\n",
      "Epoch: 2689 Train loss: 0.3294417\n",
      "Epoch: 2690 Train loss: 0.3294384\n",
      "Epoch: 2691 Train loss: 0.3294353\n",
      "Epoch: 2692 Train loss: 0.3294321\n",
      "Epoch: 2693 Train loss: 0.3294290\n",
      "Epoch: 2694 Train loss: 0.3294259\n",
      "Epoch: 2695 Train loss: 0.3294227\n",
      "Epoch: 2696 Train loss: 0.3294196\n",
      "Epoch: 2697 Train loss: 0.3294165\n",
      "Epoch: 2698 Train loss: 0.3294134\n",
      "Epoch: 2699 Train loss: 0.3294103\n",
      "Epoch: 2700 Train loss: 0.3294070\n",
      "Epoch: 2701 Train loss: 0.3294040\n",
      "Epoch: 2702 Train loss: 0.3294008\n",
      "Epoch: 2703 Train loss: 0.3293978\n",
      "Epoch: 2704 Train loss: 0.3293946\n",
      "Epoch: 2705 Train loss: 0.3293916\n",
      "Epoch: 2706 Train loss: 0.3293884\n",
      "Epoch: 2707 Train loss: 0.3293853\n",
      "Epoch: 2708 Train loss: 0.3293821\n",
      "Epoch: 2709 Train loss: 0.3293791\n",
      "Epoch: 2710 Train loss: 0.3293760\n",
      "Epoch: 2711 Train loss: 0.3293729\n",
      "Epoch: 2712 Train loss: 0.3293698\n",
      "Epoch: 2713 Train loss: 0.3293667\n",
      "Epoch: 2714 Train loss: 0.3293637\n",
      "Epoch: 2715 Train loss: 0.3293606\n",
      "Epoch: 2716 Train loss: 0.3293576\n",
      "Epoch: 2717 Train loss: 0.3293546\n",
      "Epoch: 2718 Train loss: 0.3293514\n",
      "Epoch: 2719 Train loss: 0.3293485\n",
      "Epoch: 2720 Train loss: 0.3293454\n",
      "Epoch: 2721 Train loss: 0.3293424\n",
      "Epoch: 2722 Train loss: 0.3293392\n",
      "Epoch: 2723 Train loss: 0.3293363\n",
      "Epoch: 2724 Train loss: 0.3293333\n",
      "Epoch: 2725 Train loss: 0.3293303\n",
      "Epoch: 2726 Train loss: 0.3293272\n",
      "Epoch: 2727 Train loss: 0.3293242\n",
      "Epoch: 2728 Train loss: 0.3293211\n",
      "Epoch: 2729 Train loss: 0.3293182\n",
      "Epoch: 2730 Train loss: 0.3293152\n",
      "Epoch: 2731 Train loss: 0.3293121\n",
      "Epoch: 2732 Train loss: 0.3293091\n",
      "Epoch: 2733 Train loss: 0.3293062\n",
      "Epoch: 2734 Train loss: 0.3293032\n",
      "Epoch: 2735 Train loss: 0.3293001\n",
      "Epoch: 2736 Train loss: 0.3292972\n",
      "Epoch: 2737 Train loss: 0.3292942\n",
      "Epoch: 2738 Train loss: 0.3292913\n",
      "Epoch: 2739 Train loss: 0.3292883\n",
      "Epoch: 2740 Train loss: 0.3292852\n",
      "Epoch: 2741 Train loss: 0.3292823\n",
      "Epoch: 2742 Train loss: 0.3292792\n",
      "Epoch: 2743 Train loss: 0.3292763\n",
      "Epoch: 2744 Train loss: 0.3292731\n",
      "Epoch: 2745 Train loss: 0.3292702\n",
      "Epoch: 2746 Train loss: 0.3292672\n",
      "Epoch: 2747 Train loss: 0.3292643\n",
      "Epoch: 2748 Train loss: 0.3292612\n",
      "Epoch: 2749 Train loss: 0.3292583\n",
      "Epoch: 2750 Train loss: 0.3292552\n",
      "Epoch: 2751 Train loss: 0.3292523\n",
      "Epoch: 2752 Train loss: 0.3292493\n",
      "Epoch: 2753 Train loss: 0.3292465\n",
      "Epoch: 2754 Train loss: 0.3292435\n",
      "Epoch: 2755 Train loss: 0.3292405\n",
      "Epoch: 2756 Train loss: 0.3292377\n",
      "Epoch: 2757 Train loss: 0.3292348\n",
      "Epoch: 2758 Train loss: 0.3292319\n",
      "Epoch: 2759 Train loss: 0.3292289\n",
      "Epoch: 2760 Train loss: 0.3292262\n",
      "Epoch: 2761 Train loss: 0.3292232\n",
      "Epoch: 2762 Train loss: 0.3292204\n",
      "Epoch: 2763 Train loss: 0.3292173\n",
      "Epoch: 2764 Train loss: 0.3292145\n",
      "Epoch: 2765 Train loss: 0.3292115\n",
      "Epoch: 2766 Train loss: 0.3292088\n",
      "Epoch: 2767 Train loss: 0.3292058\n",
      "Epoch: 2768 Train loss: 0.3292030\n",
      "Epoch: 2769 Train loss: 0.3292000\n",
      "Epoch: 2770 Train loss: 0.3291973\n",
      "Epoch: 2771 Train loss: 0.3291942\n",
      "Epoch: 2772 Train loss: 0.3291914\n",
      "Epoch: 2773 Train loss: 0.3291886\n",
      "Epoch: 2774 Train loss: 0.3291857\n",
      "Epoch: 2775 Train loss: 0.3291828\n",
      "Epoch: 2776 Train loss: 0.3291800\n",
      "Epoch: 2777 Train loss: 0.3291771\n",
      "Epoch: 2778 Train loss: 0.3291743\n",
      "Epoch: 2779 Train loss: 0.3291716\n",
      "Epoch: 2780 Train loss: 0.3291686\n",
      "Epoch: 2781 Train loss: 0.3291659\n",
      "Epoch: 2782 Train loss: 0.3291629\n",
      "Epoch: 2783 Train loss: 0.3291602\n",
      "Epoch: 2784 Train loss: 0.3291573\n",
      "Epoch: 2785 Train loss: 0.3291545\n",
      "Epoch: 2786 Train loss: 0.3291516\n",
      "Epoch: 2787 Train loss: 0.3291489\n",
      "Epoch: 2788 Train loss: 0.3291460\n",
      "Epoch: 2789 Train loss: 0.3291433\n",
      "Epoch: 2790 Train loss: 0.3291404\n",
      "Epoch: 2791 Train loss: 0.3291377\n",
      "Epoch: 2792 Train loss: 0.3291348\n",
      "Epoch: 2793 Train loss: 0.3291321\n",
      "Epoch: 2794 Train loss: 0.3291292\n",
      "Epoch: 2795 Train loss: 0.3291266\n",
      "Epoch: 2796 Train loss: 0.3291237\n",
      "Epoch: 2797 Train loss: 0.3291210\n",
      "Epoch: 2798 Train loss: 0.3291182\n",
      "Epoch: 2799 Train loss: 0.3291155\n",
      "Epoch: 2800 Train loss: 0.3291127\n",
      "Epoch: 2801 Train loss: 0.3291099\n",
      "Epoch: 2802 Train loss: 0.3291072\n",
      "Epoch: 2803 Train loss: 0.3291044\n",
      "Epoch: 2804 Train loss: 0.3291016\n",
      "Epoch: 2805 Train loss: 0.3290988\n",
      "Epoch: 2806 Train loss: 0.3290961\n",
      "Epoch: 2807 Train loss: 0.3290934\n",
      "Epoch: 2808 Train loss: 0.3290905\n",
      "Epoch: 2809 Train loss: 0.3290877\n",
      "Epoch: 2810 Train loss: 0.3290851\n",
      "Epoch: 2811 Train loss: 0.3290824\n",
      "Epoch: 2812 Train loss: 0.3290795\n",
      "Epoch: 2813 Train loss: 0.3290768\n",
      "Epoch: 2814 Train loss: 0.3290741\n",
      "Epoch: 2815 Train loss: 0.3290714\n",
      "Epoch: 2816 Train loss: 0.3290686\n",
      "Epoch: 2817 Train loss: 0.3290659\n",
      "Epoch: 2818 Train loss: 0.3290633\n",
      "Epoch: 2819 Train loss: 0.3290605\n",
      "Epoch: 2820 Train loss: 0.3290578\n",
      "Epoch: 2821 Train loss: 0.3290552\n",
      "Epoch: 2822 Train loss: 0.3290525\n",
      "Epoch: 2823 Train loss: 0.3290496\n",
      "Epoch: 2824 Train loss: 0.3290470\n",
      "Epoch: 2825 Train loss: 0.3290443\n",
      "Epoch: 2826 Train loss: 0.3290417\n",
      "Epoch: 2827 Train loss: 0.3290389\n",
      "Epoch: 2828 Train loss: 0.3290363\n",
      "Epoch: 2829 Train loss: 0.3290334\n",
      "Epoch: 2830 Train loss: 0.3290308\n",
      "Epoch: 2831 Train loss: 0.3290280\n",
      "Epoch: 2832 Train loss: 0.3290254\n",
      "Epoch: 2833 Train loss: 0.3290227\n",
      "Epoch: 2834 Train loss: 0.3290199\n",
      "Epoch: 2835 Train loss: 0.3290174\n",
      "Epoch: 2836 Train loss: 0.3290147\n",
      "Epoch: 2837 Train loss: 0.3290121\n",
      "Epoch: 2838 Train loss: 0.3290093\n",
      "Epoch: 2839 Train loss: 0.3290069\n",
      "Epoch: 2840 Train loss: 0.3290041\n",
      "Epoch: 2841 Train loss: 0.3290014\n",
      "Epoch: 2842 Train loss: 0.3289987\n",
      "Epoch: 2843 Train loss: 0.3289962\n",
      "Epoch: 2844 Train loss: 0.3289936\n",
      "Epoch: 2845 Train loss: 0.3289908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2846 Train loss: 0.3289883\n",
      "Epoch: 2847 Train loss: 0.3289857\n",
      "Epoch: 2848 Train loss: 0.3289830\n",
      "Epoch: 2849 Train loss: 0.3289804\n",
      "Epoch: 2850 Train loss: 0.3289778\n",
      "Epoch: 2851 Train loss: 0.3289753\n",
      "Epoch: 2852 Train loss: 0.3289725\n",
      "Epoch: 2853 Train loss: 0.3289701\n",
      "Epoch: 2854 Train loss: 0.3289672\n",
      "Epoch: 2855 Train loss: 0.3289648\n",
      "Epoch: 2856 Train loss: 0.3289621\n",
      "Epoch: 2857 Train loss: 0.3289596\n",
      "Epoch: 2858 Train loss: 0.3289569\n",
      "Epoch: 2859 Train loss: 0.3289544\n",
      "Epoch: 2860 Train loss: 0.3289518\n",
      "Epoch: 2861 Train loss: 0.3289492\n",
      "Epoch: 2862 Train loss: 0.3289466\n",
      "Epoch: 2863 Train loss: 0.3289441\n",
      "Epoch: 2864 Train loss: 0.3289415\n",
      "Epoch: 2865 Train loss: 0.3289388\n",
      "Epoch: 2866 Train loss: 0.3289363\n",
      "Epoch: 2867 Train loss: 0.3289338\n",
      "Epoch: 2868 Train loss: 0.3289312\n",
      "Epoch: 2869 Train loss: 0.3289287\n",
      "Epoch: 2870 Train loss: 0.3289260\n",
      "Epoch: 2871 Train loss: 0.3289236\n",
      "Epoch: 2872 Train loss: 0.3289209\n",
      "Epoch: 2873 Train loss: 0.3289185\n",
      "Epoch: 2874 Train loss: 0.3289159\n",
      "Epoch: 2875 Train loss: 0.3289133\n",
      "Epoch: 2876 Train loss: 0.3289107\n",
      "Epoch: 2877 Train loss: 0.3289081\n",
      "Epoch: 2878 Train loss: 0.3289056\n",
      "Epoch: 2879 Train loss: 0.3289029\n",
      "Epoch: 2880 Train loss: 0.3289005\n",
      "Epoch: 2881 Train loss: 0.3288979\n",
      "Epoch: 2882 Train loss: 0.3288953\n",
      "Epoch: 2883 Train loss: 0.3288929\n",
      "Epoch: 2884 Train loss: 0.3288903\n",
      "Epoch: 2885 Train loss: 0.3288877\n",
      "Epoch: 2886 Train loss: 0.3288853\n",
      "Epoch: 2887 Train loss: 0.3288827\n",
      "Epoch: 2888 Train loss: 0.3288802\n",
      "Epoch: 2889 Train loss: 0.3288777\n",
      "Epoch: 2890 Train loss: 0.3288752\n",
      "Epoch: 2891 Train loss: 0.3288725\n",
      "Epoch: 2892 Train loss: 0.3288701\n",
      "Epoch: 2893 Train loss: 0.3288676\n",
      "Epoch: 2894 Train loss: 0.3288652\n",
      "Epoch: 2895 Train loss: 0.3288626\n",
      "Epoch: 2896 Train loss: 0.3288601\n",
      "Epoch: 2897 Train loss: 0.3288576\n",
      "Epoch: 2898 Train loss: 0.3288551\n",
      "Epoch: 2899 Train loss: 0.3288528\n",
      "Epoch: 2900 Train loss: 0.3288502\n",
      "Epoch: 2901 Train loss: 0.3288478\n",
      "Epoch: 2902 Train loss: 0.3288453\n",
      "Epoch: 2903 Train loss: 0.3288428\n",
      "Epoch: 2904 Train loss: 0.3288403\n",
      "Epoch: 2905 Train loss: 0.3288380\n",
      "Epoch: 2906 Train loss: 0.3288355\n",
      "Epoch: 2907 Train loss: 0.3288330\n",
      "Epoch: 2908 Train loss: 0.3288306\n",
      "Epoch: 2909 Train loss: 0.3288282\n",
      "Epoch: 2910 Train loss: 0.3288257\n",
      "Epoch: 2911 Train loss: 0.3288233\n",
      "Epoch: 2912 Train loss: 0.3288207\n",
      "Epoch: 2913 Train loss: 0.3288183\n",
      "Epoch: 2914 Train loss: 0.3288159\n",
      "Epoch: 2915 Train loss: 0.3288134\n",
      "Epoch: 2916 Train loss: 0.3288109\n",
      "Epoch: 2917 Train loss: 0.3288085\n",
      "Epoch: 2918 Train loss: 0.3288062\n",
      "Epoch: 2919 Train loss: 0.3288036\n",
      "Epoch: 2920 Train loss: 0.3288013\n",
      "Epoch: 2921 Train loss: 0.3287987\n",
      "Epoch: 2922 Train loss: 0.3287962\n",
      "Epoch: 2923 Train loss: 0.3287938\n",
      "Epoch: 2924 Train loss: 0.3287913\n",
      "Epoch: 2925 Train loss: 0.3287888\n",
      "Epoch: 2926 Train loss: 0.3287865\n",
      "Epoch: 2927 Train loss: 0.3287840\n",
      "Epoch: 2928 Train loss: 0.3287816\n",
      "Epoch: 2929 Train loss: 0.3287792\n",
      "Epoch: 2930 Train loss: 0.3287768\n",
      "Epoch: 2931 Train loss: 0.3287743\n",
      "Epoch: 2932 Train loss: 0.3287721\n",
      "Epoch: 2933 Train loss: 0.3287696\n",
      "Epoch: 2934 Train loss: 0.3287673\n",
      "Epoch: 2935 Train loss: 0.3287648\n",
      "Epoch: 2936 Train loss: 0.3287625\n",
      "Epoch: 2937 Train loss: 0.3287601\n",
      "Epoch: 2938 Train loss: 0.3287577\n",
      "Epoch: 2939 Train loss: 0.3287552\n",
      "Epoch: 2940 Train loss: 0.3287529\n",
      "Epoch: 2941 Train loss: 0.3287505\n",
      "Epoch: 2942 Train loss: 0.3287482\n",
      "Epoch: 2943 Train loss: 0.3287458\n",
      "Epoch: 2944 Train loss: 0.3287435\n",
      "Epoch: 2945 Train loss: 0.3287410\n",
      "Epoch: 2946 Train loss: 0.3287387\n",
      "Epoch: 2947 Train loss: 0.3287364\n",
      "Epoch: 2948 Train loss: 0.3287340\n",
      "Epoch: 2949 Train loss: 0.3287317\n",
      "Epoch: 2950 Train loss: 0.3287292\n",
      "Epoch: 2951 Train loss: 0.3287269\n",
      "Epoch: 2952 Train loss: 0.3287246\n",
      "Epoch: 2953 Train loss: 0.3287222\n",
      "Epoch: 2954 Train loss: 0.3287200\n",
      "Epoch: 2955 Train loss: 0.3287176\n",
      "Epoch: 2956 Train loss: 0.3287153\n",
      "Epoch: 2957 Train loss: 0.3287129\n",
      "Epoch: 2958 Train loss: 0.3287106\n",
      "Epoch: 2959 Train loss: 0.3287084\n",
      "Epoch: 2960 Train loss: 0.3287058\n",
      "Epoch: 2961 Train loss: 0.3287037\n",
      "Epoch: 2962 Train loss: 0.3287012\n",
      "Epoch: 2963 Train loss: 0.3286990\n",
      "Epoch: 2964 Train loss: 0.3286966\n",
      "Epoch: 2965 Train loss: 0.3286943\n",
      "Epoch: 2966 Train loss: 0.3286919\n",
      "Epoch: 2967 Train loss: 0.3286897\n",
      "Epoch: 2968 Train loss: 0.3286873\n",
      "Epoch: 2969 Train loss: 0.3286851\n",
      "Epoch: 2970 Train loss: 0.3286827\n",
      "Epoch: 2971 Train loss: 0.3286805\n",
      "Epoch: 2972 Train loss: 0.3286782\n",
      "Epoch: 2973 Train loss: 0.3286758\n",
      "Epoch: 2974 Train loss: 0.3286736\n",
      "Epoch: 2975 Train loss: 0.3286712\n",
      "Epoch: 2976 Train loss: 0.3286690\n",
      "Epoch: 2977 Train loss: 0.3286667\n",
      "Epoch: 2978 Train loss: 0.3286644\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-cb48a409de38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mib_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-94d5706f1ccf>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, samples, labels, classes)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-7fbbeaaaca25>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mactivations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#TODO: Could be nicer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinears\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinears\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tr = Trainer(config, ib_model, optimizer)\n",
    "tr.train(x_train, y_train, c_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MI:\n",
    "    def __init__(self, activity, data_loader, binsize=0.07):\n",
    "        self.activity = activity\n",
    "        self.binsize = binsize\n",
    "        self.X = data_loader.dataset.tensors[0].numpy()\n",
    "        self.y_onehot = data_loader.dataset.tensors[1].numpy()\n",
    "        self.y_flat = np.array(list(map(np.argmax, self.y_onehot)))\n",
    "        nb_classes = self.y_onehot[0]\n",
    "        self.y_idx_label = {x : None for x in nb_classes}\n",
    "        for i in self.y_idx_label:\n",
    "            self.y_idx_label[i] = i == self.y_flat\n",
    "            \n",
    "            \n",
    "    def get_unique_probs(self, x):\n",
    "        \"\"\"\n",
    "        Taken from original paper code\n",
    "        \"\"\"\n",
    "        uniqueids = np.ascontiguousarray(x).view(np.dtype((np.void, x.dtype.itemsize * x.shape[1])))\n",
    "        _, unique_inverse, unique_counts = np.unique(uniqueids, return_index=False,\n",
    "                                                     return_inverse=True, return_counts=True)\n",
    "        \n",
    "        return np.asarray(unique_counts / float(sum(unique_counts)))\n",
    "\n",
    "    \n",
    "    def get_h(self, d):\n",
    "        \"\"\"\n",
    "        Taken from original paper code\n",
    "        \"\"\"\n",
    "        digitized = np.floor(d / self.binsize).astype('int')\n",
    "        p_ts = self.get_unique_probs( digitized )\n",
    "        #print(p_ts)\n",
    "        #print(p_ts[0])\n",
    "        #print(len(p_ts))\n",
    "        return -np.sum(p_ts * np.log(p_ts))\n",
    "\n",
    "    \n",
    "    def bin_calc_information(self, labelixs, layerdata):\n",
    "        \"\"\"\n",
    "        Taken from original paper code\n",
    "        \"\"\"\n",
    "        # This is even further simplified, where we use np.floor instead of digitize\n",
    "        nats2bits = 1.0 / np.log(2)\n",
    "\n",
    "        H_LAYER = self.get_h(layerdata)\n",
    "        #print(H_LAYER)\n",
    "        H_LAYER_GIVEN_OUTPUT = 0\n",
    "        for label, ixs in labelixs.items():\n",
    "            h = self.get_h(layerdata[ixs])\n",
    "            H_LAYER_GIVEN_OUTPUT += ixs.mean() * h\n",
    "        return nats2bits * H_LAYER, nats2bits * (H_LAYER - H_LAYER_GIVEN_OUTPUT)\n",
    "    \n",
    "    \n",
    "    def get_MI(self):\n",
    "        all_MI_XH = [] # Contains I(X;H) and stores it as (epoch_num, layer_num)\n",
    "        all_MI_YH = [] # Contains I(Y;H) and stores it as (epoch_num, layer_num\n",
    "        for epoch in self.activity:\n",
    "            temp_MI_XH = []\n",
    "            temp_MI_YH = []\n",
    "            for layer in epoch:\n",
    "                MI_XH, MI_YH = self.bin_calc_information(self.y_idx_label, layer)\n",
    "                temp_MI_XH.append(MI_XH)\n",
    "                temp_MI_YH.append(MI_YH)\n",
    "            all_MI_XH.append(temp_MI_XH)\n",
    "            all_MI_YH.append(temp_MI_YH)\n",
    "        return all_MI_XH, all_MI_YH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_inf = MI(tr.hidden_activations, eval_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "MI_XH, MI_YH = mutual_inf.get_MI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11.67815995754276,\n",
       " 11.500112268186681,\n",
       " 7.158759059715261,\n",
       " 3.5395842511907176,\n",
       " 1.1575851497464749,\n",
       " 0.2376057519060142]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MI_XH[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_info_plan(MI_XH, MI_YH):\n",
    "    running_mis_xt = np.array(MI_XH)\n",
    "    running_mis_ty = np.array(MI_YH)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.title(\"Full Data\")\n",
    "    for i in range(len(MI_XH[0])):\n",
    "        plt.plot(running_mis_xt[:, i], label=f'{i}')\n",
    "    plt.legend()\n",
    "    #ax.xaxis.set_major_formatter(ticker.FuncFormatter(self.format_epochs))\n",
    "    plt.ylabel('I(X;T)')\n",
    "    plt.savefig(f'plot_IP_FULLDATA.png')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(f'IP - Full Data')\n",
    "    c = list(range(len(running_mis_xt[:, 0])))\n",
    "    for j in range(len(MI_XH[0])):\n",
    "        plt.scatter(running_mis_xt[:, j], running_mis_ty[:, j], c=c, cmap='plasma', s=20, alpha=0.85, zorder=1)\n",
    "    for j in range(len(running_mis_xt[:, 0])):\n",
    "        plt.plot(running_mis_xt[j, :], running_mis_ty[j, :], alpha=0.1, zorder=0)\n",
    "\n",
    "    #cbar = plt.colorbar(format=ticker.FuncFormatter(self.format_epochs))\n",
    "    #cbar.set_label('Epochs')\n",
    "\n",
    "    plt.xlabel('I(X;T)')\n",
    "    plt.ylabel('I(T;Y)')\n",
    "    plt.savefig(f'IP_FULLDATA.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_info_plan(MI_XH, MI_YH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
